\clearpage
%\section*{\scalebox{1.25}{\appendixphrase}}
\section*{New Security Proof and Almost-Special-Soundness (Added June 2022)}

\label{appendix:proofs}

Although DARK does not satisfy \emph{special soundness}, it does satisfy a property that we will call \emph{almost-special-sound}, which turns out to be sufficient (i.e., using our new forking lemma we can prove that such protocols are knowledge sound). Almost-special-soundness is a weaker property than special soundness, as all protocols that satisfy special soundness also satisfy almost-special-soundness. 
%\section{Proof overview}
%Multi-round interactive public-coin protocols can be proven to be knowledge-sound by showing that they satisfy the notion of knowledge soundness. For one-round protocols (aka $\Sigma$- protocols consisting of a prover message, a verifier challenge, and a prover response), special-soundness states that there exists an efficient extractor that can extract from any set of correlated transcripts that have the same first prover message, distinct challenges and possibly distinct responses. For multi-round protocols, the notion has been extended to $k$-ary trees of transcripts where edges correspond to challenges and nodes to prover messages. A protocol is multi-round special sound if an extractor can extract from any tree where each edge's challenge is distinct from its siblings' challenges. Multi-round special sound protocols are still knowledge sound. We further generalize the notion of knowledge soundness to \emph{almost special soundness} while showing that such protocols still satisfy. Special sound protocols satisfy a predicate on each of the challenges, namely that each challenge is distinct from its siblings. This predicate holds with overwhelming probability over random challenges (for large enough challenge spaces). In almost special soundness, we generalize the set of predicates that hold over the tree. Further, we generalize the input to the predicates. \benedikt{Finish (actually we can take this out likely)}

\section{Preliminaries and Notations}
\label{appendix:prelimns}
\subsection{Integer Polynomials} If $f$ is a multivariate polynomial, then $||f||_\infty$ denotes the maximum over the absolute values of all coefficients of $f$. 

\begin{lemma}[Evaluation Bound]\label{lem:evalbound} For any $\mu$-linear integer polynomial $f$ and $m \geq 2$:
 $$\Prob_{\mathbf{x} \gets [0,m)^\mu} [|f(\mathbf{x})|\leq \frac{1}{m^\mu} \cdot ||f||_\infty]\leq \frac{3\mu}{m}$$
 \end{lemma} 

 \begin{proof}
 Let $f^{(0)}:=f$. 
 Given a vector $\mathbf{x} = (x_1,..,x_\mu)$, for each $j\in[1,\mu]$ define $f_{\mathbf{x}}^{(j)}$ to be the $\mu-j$-variate partial evaluation $f_{\mathbf{x}}^{(j)}:= f(x_1,...,x_j, X_{j+1},...,X_\mu)$. Then we can rewrite the lemma statement as:
    $$P_{\mathbf{x} \gets [0,m)^\mu} [||f_{\mathbf{x}}^{(\mu)}||_\infty\leq  \frac{1}{m^\mu} \cdot ||f^{(0)}||_\infty ]\leq\frac{ 3\mu}{m}$$	
 
We will bound the probability for random $\mathbf{x}$ that there exists any $j$ for which $||f_{\mathbf{x}}^{(j)}|| < \frac{1}{m} \cdot ||f_{\mathbf{x}}^{(j-1)}||$. If no such $j$ exists, then $||f^{(\mu)}|| \geq \frac{1}{m^\mu} \cdot ||f^{(0)}||$. 

For any $j$, we can write $f_{\mathbf{x}}^{(j)} = g(X_{j+1},...,X_\mu) + x_{j}\cdot h(X_{j+1},...,X_\mu)$ where $g,h$ are $\mu-j$ variate multilinear integer polynomials and $||f_{\mathbf{x}}^{(j-1)}|| = \max(||g||, ||h||)$ because the coefficients of $g$ and $h$ are a partition of the coefficients of $f_{\mathbf{x}}^{(j-1)}$.  Suppose now that $||f_{\mathbf{x}}^{(j)}|| < \frac{1}{m} \cdot ||f_{\mathbf{x}}^{(j-1)}||$, i.e. that $||g + x_j \cdot h|| < \frac{1}{m} \cdot \max(||g||, ||h||)$ and consider two cases: \\

\emph{Case 1: $||h|| = \max(||g||, ||h||)$}.  For any integer $\Delta \neq 0$, using the triangle inequality: 
$$||g+(x_j +\Delta) h ||=||g + x_j h +\Delta h||\geq  ||\Delta h|| -  ||g + x_j h|| >  (1 - \frac{1}{m}) \cdot ||h|| \geq \frac{1}{m} \cdot ||h||   $$

The last part of the inequality holds because $1 - \frac{1}{m} \geq \frac{1}{m}$ for any $m \geq 2$. \\

\emph{Case2: $||g|| = \max(||g||, ||h||)$}. Using the triangle inequality, 

$$\frac{1}{m} ||g|| > ||g+x_j \cdot h || \geq  ||g|| - ||x_j \cdot h||$$ 

This implies, for $m \geq 2$, that $||h|| > \frac{1}{m} \cdot ||g||$ because:

$$||x_j \cdot h|| > (1 - \frac{1}{m}) \cdot ||g||\implies ||h||> \frac{m-1}{x_j \cdot m} \cdot ||g||\geq \frac{1}{m} ||g||$$
The last step uses that $x_j\in [1,m)$. For $x_j=0$, $||g +x_j h||=||g||$. 
Finally, for any integer $\Delta$, by the triangle inequality: 

$$||g + (x_j + \Delta) \cdot h|| \geq || \Delta h|| - ||g + x_j \cdot h|| > \frac{|\Delta|}{m} \cdot ||g||  - \frac{1}{m} \cdot ||g||  = \frac{|\Delta| -1}{m} \cdot ||g||$$ 

When $|\Delta| \geq 2$ this implies that $||g + (x_j + \Delta) \cdot h|| > \frac{1}{m} \cdot ||g||$.  

In both cases, we conclude that for any choice of $(x_1,...,x_{j-1})$ for the first $j-1$ components of the random $\mathbf{x}$, which define $g$ and $h$, there are at most three choices of $x_j$ such that the event $||f_{\mathbf{x}}^{(j)}|| < \frac{1}{m} \cdot ||f_{\mathbf{x}}^{(j-1)}||$ holds true  (i.e., if true for $x_j$, then it is also true for at most $x_j + 1$ and $x_j - 1$). Thus this event occurs with probability at most $\frac{3}{m}$. Finally, by a union bound over $j$, the probability this event occurs for some index $j$ is at most $\frac{3\mu}{m}$. 


 \end{proof}

 
 \begin{lemma}[Multilinear Composite Schwartz-Zippel \cite{EPRINT:BunFis22}  ]\label{lem:CSZ}
 For all $m \geq 2$, any $\mu$-linear integer polynomial $f$, and $N \in \mathbb{Z}$ coprime to $f$, if either $\mu = 1$ and $ \log_2 N \geq \lambda$ or $\mu \geq 2$ and $\log_2 N\geq 8 \mu^2 + \log_2(2\mu)\cdot \lambda$ then:
 $$\Prob_{x\gets [0,m)^\mu} [f(x)\equiv 0 \bmod N]\leq \frac{1}{2^{\lambda}} + \frac{\mu}{m}$$
% In particular, setting $m = \mu\cdot 2^{\lambda}$ gives the probability bound $2^{-\lambda + 1}$. 
 \end{lemma} 
\cite{EPRINT:BunFis22} also provide an algorithm for computing tighter values for the MCSZ for concrete parameters for $\mu$ and $\lambda$. We present a range of values for different $\mu$ and $\lambda=120$.
   \begin{lemma}[Concrete MCSZ for 120-bit security \cite{EPRINT:BunFis22}] \label{lem:cCSZ}

 $$\Prob_{x\gets [0,m)^\mu} [f(x)\equiv 0 \bmod N]\leq 2^{-120}+\frac{\mu}{m}$$
\begin{mdframed}
 \begin{center}

\begin{tabular}{l||l}

$\mu$ &  $\lambda=120$ \\
\hline
\hline
1 & 120\\
2 & 156\\
3 & 175\\
4 & 197\\
5 & 212\\
6 & 234\\
7 & 244\\
8 & 260\\
9 & 277\\
10 & 289\\

\end{tabular}
\begin{tabular}{l||l}

$\mu$ &  $\lambda=120$ \\
\hline
\hline
11 & 301\\
12 & 315\\
13 & 331\\
14 & 344\\
15 & 354\\
16 & 366\\
17 & 381\\
18 & 391\\
19 & 407\\
20 & 416\\
\end{tabular}
\begin{tabular}{l||l}

$\mu$ &  $\lambda=120$ \\
\hline
\hline
21 & 429\\
22 & 437\\
23 & 448\\
24 & 464\\
25 & 472\\
26 & 481\\
27 & 492\\
28 & 506\\
29 & 516\\
30 & 527\\

\end{tabular}
\end{center}	
\end{mdframed}
 \end{lemma} 

\begin{fact}
\label{fact:encoding}
Let $q \in \ZZ$ be any positive integer. For any integer $E \in \ZZ$ such that $|E|\leq \frac{q^{d+2} - q}{2(q-1)}$ there exists a unique degree $d$ integer polynomial $f \in \ZZ[X]$ with $||f||_\infty \leq q/2$ such that $f(q) = E$. 
\end{fact} 
\benedikt{Add fact for multi-linear? }

We extend the integer encoding from \Cref{sec:encoding} to rational polynomials.
\begin{lemma}[Rational Encoding of multi-linear polynomials]
\label{lem:encoding}
Let $q \in \ZZ$ be any positive integer. Let $\vec{q}=[q^{2^{i-1}}]_{i=1}^\mu \in \ZZ^\mu$. Consider any $\beta_d, \beta_n \in \mathbb{N}$ such that $\beta_d \cdot \beta_n\leq \frac{q}{2}$. Let $Z = \{z \in \ZZ: |z| \leq \beta_d \}$, let $\mathcal{F} = \{ f \in \ZZ[X_1,\dots,X_\mu]: ||f||_\infty \leq \beta_n\}$ be a $\mu$-linear polynomial, and let $\mathcal{H} = \{f/z \in \mathbb{Q}[X_1,\dots X_\mu]: f \in \mathcal{F} \wedge z \in Z \}$. Then for any $h_1, h_2 \in \mathcal{H}$,  if $h_1(\vec{q}) = h_2(\vec{q})$ then $h_1 = h_2$. 
\end{lemma}
\begin{proof}
Let $h_1 = \frac{f_1}{z_1}$ and $h_2 = \frac{f_2}{z_2}$. If $h_1(\vec{q}) = h_2(\vec{q})$ then $z_1 f_2(\vec{q}) = z_2 f_1(\vec{q})$. Since $||z_2 \cdot f_1||_\infty \leq \beta_d \cdot \beta_n \leq \frac{q}{2}$ and  likewise $||z_1\cdot f_2||_\infty \leq \frac{q}{2}$. Note that there exist a unique univariate degree $2^\mu-1$ polynomial $\hat{f}_1$ that has the same coefficients as $f_1$ such that for all $q$ $f_1(\vec{q})=\hat{f}_1(q)$. Let $f_2$ be the univariate degree $2^\mu-1$ polynomial with the same coefficients as $\hat{f}_2$. It then follows from Fact~\ref{fact:encoding} that if $z_1 f_2(\vec{q})=z_1\hat{f}_2(q) = z_2 \hat{f}_1(q)= z_2 f_1(\vec{q})$ then $z_1 f_2 = z_2 f_1$, or equivalently, $h_1 = h_2$.
\end{proof}


\subsection{DARK commitments} 
We restate the DARK commitment scheme as a commitment scheme to $\mu$-linear polynomials with bounded rational coefficients. If $f$ is a $\mu$-linear polynomial then it can represent a degree $2^{\mu-1}$ univariate polynomial $\hat{f}$ with the same coefficients, as $\hat{f}(z)=f(z,z^2,\dots,z^{2^{\mu-1}})$. 
While the honest prover will commit to the integer representation of a polynomial defined over a prime field, this representation is useful in the security proof. The extractor will extract bounded rational polynomials instead of integer ones. Fortunately, we can show that given sufficiently large parameters, the commitment scheme is still binding.

Given the security parameter $\lambda$, the commitment scheme setup selects a group $\GG$ for which the random order assumption holds (with  $\lambda$-bit security) and a random generator $\gr{G} \in \GG$. A parameter $q \in \mathbb{N}$ determines a commitment message space $\mathcal{M} = \{f(X_1,\dots,X_\mu): ||f||_\infty \leq q/2 \wedge \forall i \deg_{X_i}(f_i)\leq 1 \}$. The commitment to $f(X_1,\dots,X_\mu) \in \mathcal{M}$ is $f(\vec{q}) \cdot  \gr{G}$ for $\vec{q}=(q,q^2,\dots,q^{2^{\mu-1}})$. Commitments are binding over $\mathcal{M}$ because if $f(\vec{q}) \cdot \gr{G} = f'(\vec{q}) \cdot \gr{G}$ then $(f'(\vec{q}) - f(\vec{q})) \gr{G} = 0$. This breaks the order assumption for $\GG$ unless $ f'(\vec{q}) =  f(\vec{q})$, in which case $f' = f$ by Fact~\ref{fact:encoding}. 

If we expand the valid openings of the commitment scheme to include rational polynomials of the form $f/z$, where $f \in \ZZ[X]$, $z \in \ZZ$, so that $(f,D)$ is an opening of $\gr{C}$ to $f/z$ iff $z \cdot \gr{C} = f(\vec{q}) \cdot \gr{G}$, then the scheme is binding over the message space $\mathcal{M}(\beta_n, \beta_d) =  \{f(X)/z: f \in \ZZ[X], z \in \ZZ, \gcd(f,z) = 1, ||f||_\infty \leq \beta_n, |z| \leq \beta_d \}$ so long as $\beta_n \cdot \beta_d \leq \frac{q}{2}$. 
Openings to rationals are equivalent to what has been previously described as \emph{relaxed openings}, whereby $\gr{C}$ is opened to $f$ by opening $z \cdot \gr{C}$ to $z \cdot f$ for $z \in \mathbb{Z}$~\cite{C:BDFG21}. 

\begin{lemma}[DARK commitment Security]
\label{lem:darkcommit}
	The commitment scheme $(\setup,\commit, \verify)$ to integer $\mu$-linear polynomials: 
	\begin{itemize} 
	\item $\setup(\secpar,\beta_n\in \ZZ,\beta_d \in \ZZ)$: sample $\mathbb{G} \gets \ggen(\secpar) ,\Generator \gets \GG$, return $\crs := (\mathbb{G}, \gr{G}, q =2 \beta_n\beta_d)$
	\item $\commit(\crs,f\in \mathcal{M}(\beta_n,\beta_d)):$ return $f(\vec{q}) \cdot \gr{G} $ for $\vec{q}=(q,q^2,\dots,q^{\mu-1})\in \ZZ^{\mu}$
	\item $\open(\crs,C\in \GG,h = f/N  \in \mathcal{M}(\beta_n,\beta_d) )$: return $\predicate{N\cdot\Commitment = f(\vec{q})\cdot \Generator} $
	\end{itemize} 
	is binding over the rational polynomial set $\mathcal{M}(\beta_n, \beta_d)$ under the random order assumption (\ref{assum:randomorder}), i.e. for any polynomial time adversary $\adv$ $$P\left[\begin{array}{c} 
	\open(\crs,C,h)=\open(\crs,C,h')=1\\
	h\neq h' 
\end{array}
 \middle|\begin{array}{c}
(h,h',C) \in \mathcal{M}(\beta_n,\beta_d)^2 \times \GG  \gets \adv(\crs)\\	
\crs \gets \setup(\secpar,\beta_n,\beta_d)
\end{array}
	 \right]<\negl$$
\end{lemma}
%The commitment scheme is binding over $\mathcal{M}$, but only provides an efficient way to commit to integer polynomials in $\mathcal{M}$. The commitment to $f(X) \in \mathcal{M}$ is $f(q) \cdot  \gr{G}$, while $f(X)/z$ is a valid opening of $\gr{C}$ iff $z \cdot \gr{C} = f(q) \cdot \gr{G}$. 
\begin{proof}
To see why this is binding over $\mathcal{M}(\beta_n, \beta_h)$, suppose that both $h=\frac{f}{N}$ and $h'=\frac{f'}{N'}$ are valid openings of a commitment $\gr{C}$ to distinct rational polynomials $h, h' \in \mathcal{M}(\beta_n, \beta_d)$. This implies that $N\cdot \gr{C} = f(\vec{q}) \cdot \gr{G}$ and $z' \cdot \gr{C} = f'(\vec{q}) \cdot \gr{G}$. Hence, $v =  z \cdot f'(\vec{q}) - z' \cdot f(\vec{q})$ is a multiple of the order of $\gr{G}$, i.e. $v \cdot \gr{G} = 0$. Moreover, by Lemma~\ref{lem:encoding}, $h(\vec{q}) \neq h'(\vec{q})$, which implies $v \neq 0$. This breaks the random order assumption for $\GG$. It is important to note that the openings $(f, z)$ and $(f', z')$ need not be co-prime elements of bounded norm; it suffices that $h = f/z$ and $h' = f'/z'$ have bounded norm numerators and denominators in reduced fraction form, i.e. $h, h' \in \mathcal{M}(\beta_n, \beta_d)$. 
\end{proof}



\subsection{IP Transcript Trees}\label{sec:IPtrees}

Let $(P,V)$ be a $\mu$-round public coin interactive protocol. A $\mu$-round public-coin protocol $(P,V)$ consists of $\mu$-rounds of messages between the prover and verifier, where in each round the prover sends a message to the verifier and the verifier responds with $x \leftarrow \mathcal{X}$ sampled uniformly from the challenge space $\mathcal{X}$. At the end of the protocol, the verifier outputs either $accept$ or $reject$. By convention, the protocol starts with the prover's first message and ends with the prover's last message. A \emph{transcript} thus contains $\mu+1$ prover messages and $\mu$ challenges. We will denote transcripts by a $\mu \times 2$ matrix $A$ such that $A(0,0)$ is the protocol input $\mathsf{x}$, $A(0, 1)$ is the prover's first message, and for all $i ≥ 1$, $A(i, 0)$ is the verifier's $ith$ round challenge and $A(i,1)$ is the prover's $ith$ round response.  We restrict our attention to protocols in which the verifier's decision is a deterministic function $D_V$ of the transcript, which is true of the DARK protocol, but is also without loss of generality. An \emph{accepting transcript} is an array $A$ such that $D_V(A) = accept$. 

A $k$-ary \emph{transcript tree} for $(P,V)$ is a labelling of a $\mu$-depth $k$-ary tree such that the labels on every root-to-leaf path forms an accepting $(P,V)$ transcript.  It will be convenient to order the nodes of the tree according to a depth-first reverse topological sort (aka post-order tree traversal). This is a topological sorting of the tree with directed edges flowing from leaves to root which places left subtrees before right subtrees. This ordering associates each node with an index in $[1,N]$ where $N = \textsf{size}(\mu, k) = \frac{k^{\mu+1} - 1}{k-1}$. 

A \emph{post-order labelling} of the tree is a function $L:[1,N] \rightarrow \mathcal{X} \times \mathcal{M}$ where $\mathcal{X}$ is the verifier's challenge set and $\mathcal{M}$ is the space of prover messages. We can think of the first component (i.e., the verifier challenge) as a label on the node's incoming edge and the second component (i.e., prover's response) as a label on the node itself. The root has no incoming edge, but the root label's first component is the protocol input. For any root-to-leaf path of nodes with indices $\{v_0,...,v_\mu\}$ the labelling $L$ defines the matrix $A$ such that $L(v_i) = (A(i, 0), A(i, 1))$ and $A$ is an accepting transcript. Given a label $L(v)$ for $v < N$ (non-roots) we will use the notation $L(v)_0$ to denote the first component of the label containing the verifier's challenge and $L(v)_1$ the second component containing the prover's response. Finally, we define a $k$-ary \emph{forking transcript tree} to be a $k$-ary transcript tree in which the challenge labels on all edges sharing a common parent are distinct.

We may refer to the \emph{level} of a node in the tree. The root of a tree is always at \emph{level 0} and the leaves of a depth $\mu$ tree are at \emph{level $\mu$}. The \emph{height} of node at level $\ell$ within a $\mu$-depth tree is $\mu - \ell$. For each $v \in [1,N]$ let $v^*$ denote the largest index $v^* < v$ such that the node at index $v^*$ does not belong to the subtree extending from $v$. Note that for nodes on the leftmost path of the tree $v^*$ does not exist so we denote it by $\bot$. For each $v \in [1,N]$ let $L_v:[1,v] \rightarrow \mathcal{X} \times \mathcal{M}$ denote the restriction of $L$ to the subset $[1,v^*]$. 
Similarly, for any $S \subseteq [1,N]$ let $L_S: S \rightarrow \mathcal{X} \times \mathcal{M}$ denote the restriction of the labelling $L$ to the subset of node indices $S$. For any $v \in [1, N]$ let $S_v \subseteq [1,N]$ denote the indices of all nodes in the subtree rooted at node $v$. $L_{S_v}$ thus denotes the labelling of the subtree $S_v$. Note that $L_{v^*}$ is not the same as $L_{S_{v^*}}$. 
\begin{figure}

\begin{forest}
for tree={%
    l sep=2cm,
    s sep=0.1cm,
    minimum height=1cm,
    minimum width=1cm,
    align=center,
    draw,
  },
my edge label/.style={
    edge label={node [midway,above,sloped,font=\large] {$#1$}}
  },
level label/.style={
    label={[font=\scriptsize]left:#1},
  },
  before drawing tree={
    tikz+={
      \node [anchor=mid east, font=\sffamily] (m) at (current bounding box.west |- .mid) {Level 0};
    },
    tempcounta'=0,
    for tree={
      if={% if the current level exceeds the value of tempcounta
        >OR>{level}{tempcounta}%
      }{% then step the count and add the level marker
        tempcounta'+=1,
        tikz+/.process={ Rw {tempcounta} {
            \node [anchor=mid east, font=\sffamily] at (m.east |- .mid) {Level #1};
          }%
        },
      }{},
    },
  },
   [$L(13)$:\\ ${\mathsf{x},A(0,1)}$\\ ${v^*=\bot}$, baseline,  
   [$L_1(4)$:\\
    ${A(1,1)}$\\ ${v^*=\bot}$ ,my edge label={L(4)_0} [$L_1(1)$:\\
     ${A(2,1)}$\\ ${v^*=\bot}$, my edge label={L(1)_0}][$L_1(2)$:\\ ${A(2,1)}$\\ ${v^*=1}$, my edge label={L(2)_0}][$L_1(3)$:\\
      ${A(2,1)}$\\ ${v^*=2}$, my edge label={L(3)_0}]]<to>
 [$L_1(8)$:\\ ${A(1,1)}$\\ ${v^*=4}$, my edge label={L(8)_0}
,
 align=center[$L_1(5)$:\\
  ${A(2,1)}$\\ ${v^*=4}$, my edge label={L(5)_0}][$L_1(6)$:\\
   ${A(2,1)}$\\ ${v^*=5}$, my edge label={L(6)_0}][$L_1(7)$:\\
    ${A(2,1)}$\\ ${v^*=6}$, my edge label={L(7)_0}]]<test>
  [$L_1(12)$:\\
   ${A(1,1)}$\\ ${v^*=8}$, my edge label={L(12)_0}
,
 align=center[$L_1(9)$:\\
  ${A(2,1)}$\\ ${v^*=8}$, my edge label={L(9)_0}
][$L_1(10)$:\\
 ${A(2,1)}$\\ ${v^*=9}$, my edge label={L(10)_0}][$L_1(11)$:\\
  ${A(2,1)}$\\ ${v^*=10}$\\, my edge label={L(11)_0}]]<test>
  ]
\end{forest}
\caption{IP transcript tree for $\mu=k=3$. Nodes and edges are labeled using post-order labeling. We also indicate $v^*$ for every node.}
\label{fig:iptree}

\end{figure}
\subsection{Path Predicate Forking Lemma}
The standard forking lemma for $\mu$-round public coin interactive protocols characterizes the efficiency of generating a $k$-ary $\mu$-depth transcript tree for which the challenges labeling the children within the tree \emph{fork}, i.e. are distinct. More precisely, the forking lemma says that given any adversarial prover $\mathcal{A}$ that may deviate from the honest protocol but causes the verifier to accept with probability $\epsilon$, there is a tree generation algorithm that has only black-box access to $\mathcal{A}$, runs in time $t \in O(\frac{\lambda}{\epsilon} \cdot k^\mu \cdot (\mu + t_V))$, where $t_V$ is the running time of the verifier's decision algorithm, and succeeds with probability $1 - t \cdot \negl$ in producing a transcript tree with the forking property. 

 Our \emph{path predicate forking lemma} generalizes the property of the transcript tree that can be generated by considering arbitrary predicates on partial labelings of the tree. In the standard forking lemma, the predicate would simply be that new challenges are distinct from previous challenges. The lemma considers predicates for each node $v \in [1,N]$ at level $\ell_v$ of the form $\pi_v: (\mathcal{X}\times \mathcal{M})^{[1,v^*]} \times \mathcal{X}^{\mu - \ell_v} \rightarrow \{0,1\}$, i.e. each predicate $\pi_v$ takes as input a labelling function $L_{v^*}$ for the partial set of nodes $[1,v^*]$ and a vector of challenges $\mathbf{x} \in \mathcal{X}^{\mu - \ell_v}$. 
 The vector of challenges will represent \emph{the leftmost} path down the tree starting from $v$, which by definition is independent of the partial labeling $L_{v^*}$. We denote the indices of the leftmost path from $v$ to the leaves as $\textsf{lpath}_v$ and the challenge labels along this path assigned by $L$ as $L(\textsf{lpath}_v)_0$. For example in \Cref{fig:iptree} the predicate $\pi_8$ for node $8$ would take as input the subtree spanned by $4$ and the challenge $L(5)_0$. The lemma says that if $\pi_v(L_{v^*}, \mathbf{x}) = 1$ with overwhelming probability $1 - \negl$ for any post-order labeling $L:[1,N] \rightarrow \mathcal{X} \times \mathcal{M}$ of the $k$-ary $\mu$-depth tree, any node $v$ in the tree, and $\mathbf{x}$ sampled randomly, then the transcript generation algorithm produces a transcript tree represented by some post-order labeling $L$ for which $\pi_v(L_{v^*}, L(\textsf{lpath}_v)_0) = 1$ for all $v$ in the tree. In fact, the lemma is even more general as it has a weaker requirement that $\pi_v(L_v^*, \mathbf{x}) = 1$ with overwhelming probability conditioned on $\pi_u(L_u^*, L(\textsf{lpath}_u)_0) = 1$ for all $u \leq v^*$. The standard forking lemma is a special case where $\pi_v$ checks that the challenge label on $v$ is distinct from the challenge labels on any of its left siblings. The challenge label $L(v)_0$ on $v$ is the first component of $L(\textsf{lpath}_v)_0$ and the challenge labels on the left sibling(s) of $v$, assuming $v$ is not the first child, are included in $L_{v^*}$. 
 
 \paragraph{Proof Overview} 
 We will begin with a high level overview of the proof. The algorithm is exactly the same as the recursive tree generation algorithm for the standard forking lemma. The difference is only in the analysis. The standard forking lemma considers predicates $\pi_v(L_{v^*}, x)$ that are functions only of the challenges assigned by $L_{v^*}$ to left sibling nodes of $v$ and a single (fresh) $x \in \mathcal{X}$ rather than a vector, and are independently true with overwhelming probability. %(The forking lemma for "special soundness" coincides with the case where each predicate $\pi_v$ expresses that the challenge $x$ is distinct from the challenges that $L_{v^*}$ assigned to left siblings of $v$ and the challenge space $\mathcal{X}$ is exponentially large). 

Just as in the standard forking lemma, the analysis is a simple union bound. First, the tree generation algorithm is transformed to a Monte Carlo algorithm that runs for $t \in \poly$ steps and succeeds with overwhelming probability. The standard forking lemma is based on the observation that a $t$-step algorithm makes at most $t$ samples from $\mathcal{X}$ and thus the predicates hold true for all sampled challenges with probability at least $1 - t\cdot \negl$. In our case, the analysis is very similar. Let $L$ denote the labelling returned by the Monte Carlo tree generation algorithm. We begin with the observation that this tree generation algorithm constructs the labelling in depth-first post-order. In particular, when the transcript tree generation algorithm visits a node $v$ at heigh $h_v$ it has already derived a partial labelling $L_{v^*}$. It samples a random vector $\mathbf{x} \in \mathcal{X}^{h_v}$ and attempts to derive a valid transcript for $\mathsf{lpath}_v$ using this challenge vector $\mathbf{x}$. If it succeeds then it sets $L(\mathsf{lpath}_v)_0 = \mathbf{x}$, otherwise the entire vector $\mathbf{x}$ is discarded and it tries again starting from $v$. Suppose there exists some $v$ such that $\pi_v(L_{v^*}, L(\mathsf{lpath}_v)_0) = 0$ and let $v$ be the lowest index node with this property.  This would imply that there occurred an event where the algorithm had already constructed $L_{v^*}$ satisfying $\pi_u(L_{u^*}, L(\mathsf{lpath}_u)_0) = 1$ for all $u \leq v^*$ and then sampled $\mathbf{x} \leftarrow \mathcal{X}^{h_v}$, setting $L(\mathsf{lpath}_v)_0 = \mathbf{x}$, such that $\pi_v(L_{v^*}, \mathbf{x}) = 0$. However, by hypothesis this event occurs with probability $\negl$ over random $\mathbf{x}$. Since the algorithm runs for only $t \in \poly$ steps, an event of this kind occurs with probability at most $t \cdot \negl$. 

Thus, we obtain a Monte Carlo algorithm that returns a transcript tree where all the predicates are satisfied with overwhelming probability. %This can be transformed back into a Las Vegas algorithm that runs in expected time $\poly$. 

 
 \begin{lemma}[Path Predicate Forking Lemma]\label{lem:ppfl}
 Let $(P, V)$ be a $\mu$-round public-coin protocol with prover message space $\mathcal{M}$ and verifier challenge space $\mathcal{X}$. For each node $v \in [1,N]$ of a $\mu$-depth $k$-ary balanced tree on $N = \textsf{size}(\mu, k)$ nodes, let $h_v$ denote the height of $v$. Let $\{\pi_v: v \in [1,N]\}$ denote a set of predicates, where $\pi_v(L_{v^*}, \mathbf{x})$ is a function of the partial labelling $L_{v^*}$ and challenge vector $\mathbf{x} \in \mathcal{X}^{h_v}$, with the property that for any post-order labelling function $L:[1,N] \rightarrow \mathcal{X} \times \mathcal{M}$ and any $v \in [1,N]$: 

$$Pr_{\mathbf{x} \leftarrow \mathcal{X}^{h_v}}[ \pi_v(L_{v^*}, \mathbf{x}) = 1 \ | \ \forall_{u \leq v^*} \pi_u(L_{u^*},L(\textsf{lpath}_u)_0) = 1] \geq 1 - \delta$$

Let $t_V$ denote the worst-case running time of the verifier's decision algorithm $D_V$. There is an algorithm $\textsf{Tree}^\mathcal{A}(\mathsf{z})$ that, given a security parameter $\lambda \in \mathbb{N}$ and oracle access to an adversarial prover $\mathcal{A}$ that causes $V$ to accept with probability $\epsilon$ on public input $\mathsf{z}$, runs in time at most $t = 2\lambda \cdot \frac{k^\mu}{\epsilon} \cdot (\mu + t_V)$ and with probability at least $1 - t \cdot\delta - 2^{-\lambda}$ outputs a $k$-ary transcript tree with post-order labeling $L:[1,N] \rightarrow \mathcal{X}\times \mathcal{M}$ such that $\pi_v(L_{v^*}, L(\textsf{lpath}_v)_0) = 1$ for all $v \in [1,N]$.  	
 \end{lemma}
 
 
 \begin{proof} 
	We will first describe a Las Vegas tree-finding algorithm that runs in expected polynomial time as we can then transform it to a Monte Carlo algorithm with a finite runtime and overwhelming success probability. 

\paragraph{Tree finding algorithm} 
The tree-finding algorithm $\mathsf{Tree}(k,\mathsf{z})$ begins by sampling a random tape $\sigma$ for the adversary. Let $A(\sigma)$ denote the \emph{deterministic}\footnote{Any probabilistic adversarial algorithm can be represented by a deterministic algorithm that takes as input a random tape.} adversary with fixed random tape $\sigma$. For all $i \in [0, \mu]$ define $T_i(\sigma, k, \mathsf{z}, x_1,...,x_i)$ as follows: 

\paragraph{Algorithm $T_i(\sigma, k, \mathsf{z}, x_1,...,x_i)$:}
\begin{itemize}
\item \textbf{If $i = \mu$:} Simulate the protocol with $\mathcal{A}(\sigma)$ as the prover and fixing the verifier's challenges $\mu$ ordered challenges to the values $x_1,...,x_\mu$. If the verifier outputs 1 during this simulation then return the protocol transcript $tr$, and otherwise return $\mathsf{fail}$. 

\item \textbf{Else if $0 \leq i < \mu$:} Sample $x_{i+1} \gets \mathcal{X}$ and run $T_i(\sigma, k,y, x_1,...,x_{i+1})$. This either returns $\mathsf{fail}$ or a transcript tree denoted $\textsf{tree}$. If it returns $\mathsf{fail}$, then output $\mathsf{fail}$. Otherwise, save the pair $(x_{i+1}, \textsf{tree})$. If $i < \mu -1$ then $\textsf{tree}$ is a tree of accepting transcripts that share a common prefix for the first $i+1$ rounds, which includes the challenges $x_1,...,x_{i+1}$. If $i+1 = \mu$ then $\textsf{tree}$ is a single accepting transcript. Repeat this process as many times as needed, each time sampling a fresh $x'_{i+1}$, running $T_i(\sigma, y, x_1,...,x'_{i+1})$, ignoring the runs that $\mathsf{fail}$, saving the succesful challenge/tree pairs until $k$ pairs have been recorded. Together the transcripts in all $k$ recorded trees form one larger tree of accepting transcripts that share a commmon prefix $\textsf{tr}_\textsf{pre}$ for the first $i$ rounds of messages with fixed challenges $x_1,...,x_i$.
\end{itemize}

$\textsf{Tree}(k, \mathsf{z})$ repeatedly samples $\sigma$ and runs $T_0(\sigma, k,\mathsf{z})$ until it outputs a tree of accepting transcripts.

We now analyze the expected runtime of $\mathsf{Tree}(k, \mathsf{z})$ and success probability of returning an $k$-ary tree of accepting transcripts given that $\mathcal{A}$ succeeds with probability $\epsilon$. $T_0(\sigma,k, \mathsf{z})$ returns $\mathsf{fail}$ iff the first iteration of each subroutine $T_i$ returns $\mathsf{fail}$ for $i = 1$ to $\mu$. The probability this happens is equal to the probability that $T_\mu(\sigma, y, x_1,...,x_\mu)$ outputs $\mathsf{fail}$ for a uniformly distributed challenge tuple $(x_1,...,x_\mu)$. This is equal to the failure probability of $\mathcal{A}(\sigma)$, i.e. $1 - \epsilon$. Thus, $\mathsf{Tree}(k, \mathsf{z})$ calls $T_0$ in expectation $1/\epsilon$ times. Letting $t_0$ be a random variable for the runtime of $T_0(\sigma, \mathsf{z})$ over random $\sigma$, the expected runtime of $\mathsf{Tree}(k, \mathsf{z})$ is $t_0/\epsilon$. 


It remains to analyze the expected runtime $\mathbb{E}[t_0]$ of $T_0(\sigma, \mathsf{z})$. Each call to $T_i(\sigma, k, \mathsf{z}, x_1,...,x_i)$ for $i \in [1,\mu]$ that occurs in the execution trace of $T_0(\sigma, k, \mathsf{z})$ is on i.i.d. uniformly distributed challenges $x_1,...,x_i$. Let $t_i$ be a random variable denoting the runtime of $T_i(\sigma, k, \mathsf{z}, x_1,...,x_i)$ over a uniformly distributed challenge prefix $\mathbf{x}_i = (x_1,...,x_i)$ and uniformly distributed $\sigma$. We omit the time to sample a random challenge from the runtime analysis as this will only affect the runtime up to a constant factor. Since $T_\mu(\sigma, k, \mathsf{z}, \mathbf{x}_\mu)$ makes $\mu$ calls to the oracle $\mathcal{A}$ and one call to the verifier's decision algorithm $D_V$ its runtime is at most $\mu + t_V$, where $t_V$ is the worst case running time of $D_V$.  

For $i < \mu$, $T_i(\sigma, k,y, \mathbf{x}_i)$ outputs $\mathsf{fail}$ iff the first call to each $T_{j}$ subroutine for $j \in [i+1,\mu]$ returns $\mathsf{fail}$, in which case the runtime is $t_\mathcal{A}$. The probability $T_i(\sigma, k, \mathsf{z}, \mathbf{x}_i)$ outputs $\mathsf{fail}$ for random $\sigma$ and $\mathbf{x}_i$ is again equal to the failure probability of $\mathcal{A}(\sigma)$, i.e. $1 - \epsilon$. If it does not output $\mathsf{fail}$, then in expectation it runs an additional $(k-1)/\epsilon$ iterations of $T_{i+1}(\sigma, k, \mathsf{z}, \mathbf{x}_i, x_{i+1})$ sampling a fresh $x_{i+1}$ for each iteration. Thus, the expected runtime $\mathbb{E}(t_i)$ is: 

$$ \mathbb{E}[(1- \epsilon)\cdot t_\mathcal{A} +  (k-1)\cdot t_{i+1}]  \leq \mathbb{E}[t_{i+1} \cdot k]$$

This recurrence relation shows: 
$$\mathbb{E}[t_0] \leq \mathbb{E}[t_\mu \cdot k^\mu] $$

Thus, we have shown that the expected runtime of $\mathsf{Tree}(k,\mathsf{z})$ is $\mathbb{E}[t] \leq \frac{k^\mu}{\epsilon} \cdot (\mu + t_V)$.

\medskip 

By standard techniques\footnote{Run $\lambda$ independent instances in parallel for $2 \cdot \mathbb{E}[t]$ steps. By Markov, each instance terminates (i.e., succeeds) with probability at least $1/2$. The probability none succeed is at most $2^{-\lambda}$}, the Las Vegas algorithm $\mathsf{Tree}(k,\mathsf{z})$ may be transformed to a Monte Carlo algorithm that runs for $2\lambda \cdot \mathbb{E}[t])$ steps and succeeds except with probability $1-2^{-\lambda}$.

\paragraph{Transcript tree property analysis} 
The transcript tree labels returned by $\mathsf{Tree}(k,\mathsf{z})$ are computed in depth-first post-order by the Monte Carlo tree generation algorithm. Let $L$ denote this post-order labeling. Consider any node $v$ that is labeled with challenge $L(v)_0 = x$ in the tree. Let $i$ denote the level of $v$ within the tree and let $\mathbf{x} = (x_1,..,x_{i-1}, x, x_{i+1},...,x_\mu)$ denote the vector of challenge labels assigned to the path starting from the root to $v$ and following the left-most path down the tree from $v$. During the execution of $\mathsf{Tree}(k, \mathsf{z})$ the following event occurred: immediately after $x$ was sampled as a candidate label for $v$, the challenges $x_{i+1},...,x_\mu$ were sampled uniformly and independently such that $\mathcal{A}(\sigma, k, \mathsf{z}, \mathbf{x})$ succeeded (i.e., produced a valid transcript). If this event had not occurred (i.e., $\mathcal{A}(\sigma, k, \mathsf{z}, \mathbf{x})$ failed) then $x$ would have been discarded and the process would have been repeated. 

In other words, when the transcript tree generation algorithm visits a node $v$ it has already derived a partial labelling $L_{v^*}$ for $[1,v^*]$ where $v^* ≤ v$ is not in any subtree extending from $v$. It samples a random vector $\mathbf{x} \in \mathcal{X}^{h_v}$ and attempts to derive a valid transcript for $\mathsf{lpath}_v$ using this challenge vector $\mathbf{x}$. If it succeeds then it sets $L(\mathsf{lpath}_v)_0 = \mathbf{x}$, otherwise the entire vector $\mathbf{x}$ is discarded and it tries again starting from $v$. Suppose there exists some $v$ such that $\pi_v(L_{v^*}, L(\mathsf{lpath}_v)_0) = 0$ and let $v$ be the lowest index node with this property.  This would imply that there occurred an event where the algorithm had already partially constructed $L$ such that $\pi_u(L_{u^*}, L(\mathsf{lpath}_u)_0) = 1$ for all $u \leq v^*$ and then subsequently sampled $\mathbf{x} \leftarrow \mathcal{X}^{h_v}$, setting $L(\mathsf{lpath}_v)_0 = \mathbf{x}$, such that $\pi_v(L_{v^*}, \mathsf{x}) = 0$. However, by hypothesis this event occurs with probability $\delta$ over random $\mathbf{x}$. The algorithm runs for at most $t = \frac{2\lambda}{\epsilon} k^\mu \cdot (\mu + t_V)$ steps in total, hence by a union bound the probability that an event of this kind occurs at all is at most $t \cdot \delta$. 

Thus, we obtain a Monte Carlo extraction algorithm that returns a transcript tree where all the predicates are satisfied with overwhelming probability (for appropriate setting of the parameters). More precisely, for any security parameter $\lambda \in \mathbb{N}$ and for $t = \frac{2\lambda}{\epsilon} \cdot k^\mu \cdot (\mu + t_V)$ the extraction algorithm runs in time at most $t$ and (by a union bound) succeeds in returning a transcript tree labeling $L$ where, for all $v$, $\pi_v(L_{v^*}, L(\mathsf{lpath}_v)_0) = 1$ with probability at least  $1 - t\cdot \delta - 2^{-\lambda}$.   %This can be transformed back into a Las Vegas algorithm that runs in expected time $\poly$. 


 \end{proof}

 
\subsection{Knowledge Soundness}
An NP relation $\mathcal{R}$ is a subset of strings $x, w \in \{0,1\}^*$ such that there is a decision algorithm to decide $(x, w) \in \mathcal{R}$ that runs in time polynomial in $|x|$ and $|w|$. The language of $\mathcal{R}$, denoted $\mathcal{L}_R$, is the set $\{x \in \{0,1\}^*: \exists w \in \{0,1\}^* \ s.t. \ (x, w) \in \mathcal{R} \}$. The string $w$ is called the \emph{witness} and $x$ the \emph{instance}.
An \defn{interactive proof of knowledge} for an NP relation $\mathcal{R}$ is a special kind of two-party interactive protocol between a prover denoted $\prover$ and a verifier denoted $\verifier$, where $\prover$ has a private input $w$ and both parties have a common public input $x$ such that $(x,w) \in \mathcal{R}$. Informally, the protocol is \emph{complete} if $\prover(x, w)$ always causes $\verifier(x)$ to output 1 for any $(x, w) \in \mathcal{R}$. The protocol is \emph{knowledge sound} if there exists an extraction algorithm $\mathcal{E}$ called the \emph{extractor} such that for every $x$ and adversarial prover $\mathcal{A}$ that causes $\verifier(x)$ to output 1 with non-negligible probability, $\mathcal{E}$ outputs $w$ such that $(x, w) \in \mathcal{R}$ with overwhelming probability given access\footnote{The extractor can run $\mathcal{A}$ for any specified number of steps, inspect the internal state of $\mathcal{A}$, and even rewind $\mathcal{A}$ to a previous state.} to $\mathcal{A}$. 

\begin{definition} [Interactive Proof of Knowledge]\label{def:proof}
  
An interactive protocol $\Pi = (\prover, \verifier)$ between a prover $\prover$ and verifier $\verifier$ is a proof of knowledge for a relation $\mathcal{R}$ with knowledge error $\delta: \mathbb{N} \rightarrow [0,1]$ if the following properties hold, where on common input $x$ and prover witness $w$ the output of the verifier is denoted by the random variable $\langle \prover(x,w), \verifier(x) \rangle$:

\begin{itemize}
\item \underline{Perfect Completeness:} for all $(x,w) \in \mathcal{R}$
\begin{small}
\[
\Pr \left[
         \ \langle \prover(x,w), \verifier(x) \rangle = 1  
\right]  = 1 
 \]
 \end{small}
\item \underline{$\delta$-Knowledge Soundness:}
There exists a polynomial $\textsf{poly}(\cdot)$ and a probabilistic oracle machine $\mathcal{E}$ called the \emph{extractor} such that given oracle access to any adversarial interactive prover algorithm $\mathcal{A}$ and any input $x \in \mathcal{L}_R$ the following holds: if
$$\mathbb{P}\left[\langle \mathcal{A}(x), \verifier(x) \rangle = 1 \right] = \epsilon(x)$$
 then $\mathcal{E}^\mathcal{A}(x)$ with oracle access to $\mathcal{A}$ runs in time $\frac{\mathsf{poly}(|x|)}{\epsilon(x)}$ and outputs $w$ such that $(x, w) \in R$ with probability at least $1 - \frac{\delta(|x|)}{\epsilon(x)}$. 
\end{itemize} 
An interactive proof is ``knowledge sound", or simply a ``proof of knowledge", if has negligible knowledge error $\delta$. 
\end{definition} 
\begin{remark} Definition~\ref{def:proof} places no restriction on the runtime of the adversary, however, it does not guarantee extraction from an adversary that succeeds with sufficiently small $\epsilon(x)$ such that $\epsilon(x) \leq  \delta(|x|)$. For $\mathcal{R}$ in NP, this definition of knowledge soundness implies the alternative formulation of Bellare and Goldreich~\cite{C:BelGol92}, which says that the protocol has knowledge error $\delta(|x|)$ if there exists an extractor that succeeds in expected time $\frac{\textsf{poly}(|x|)}{\epsilon(x) - \delta(|x|)}$. An extractor which succeeds with probability $p = 1 - \frac{\delta(|x|)}{\epsilon(x)}$ in $t = \frac{\mathsf{poly}(|x|)}{\epsilon(x)}$ steps can run repeatedly (for $t$ steps per iteration) on fresh randomness until it obtains a witness for the relation, which it can verify efficiently. It will succeed in an expected $\frac{t}{p} =  \frac{\textsf{poly}(|x|)}{\epsilon(x) - \delta(|x|)}$ steps. Finally, this has been shown to imply another equivalent formulation which requires the extractor to run in $O(\textsf{poly}(|x|))$ steps and succeed with probability $\frac{\epsilon(x) - \delta(|x|)}{q(|x|)}$ for some polynomial $q$. It is easy to see this implies the former because such an extractor can be repeated, succeeding in expected time $\frac{q \cdot \textsf{poly}(|x|)}{\epsilon(x) - \delta(|x|)}$. 	
\end{remark}


%that any protocol with this property also satisfies Definition~\ref{def:proof} because we can run the extractor $\frac{1}{\epsilon(x)}$ independent times. The probability all repetitions fail is bounded by $(1 - \frac{\epsilon(x) - \delta(|x|)}{\textsf{poly}(|x|)})^{\frac{1}{\epsilon(x)}$

 %As long as there exists a polynomial $p$ such that $\epsilon \cdot (1 - \frac{1}{p(\lambda)}) \geq \delta(\lambda)$ then the extractor succeeds with probability $1/p(\lambda)$ and thus can be repeated $\poly$ number of times to amplify the success probability. Informally, if a protocol is knowledge sound according to this definition, then any adversarial prover who does not know a witness succeeds with probability at most $O(\sqrt[c]{\delta(\lambda)})$.
 
\if 0 
\begin{definition} [Interactive Proof with Efficient\footnotemark \ Prover]\label{def:proof}
 \footnotetext{A classical interactive proof does not require the prover to be efficient. However, our definition of an interactive proof with efficient prover should also not be confused with an interactive \emph{argument}, which only requires soundness against efficient adversaries. In our definition, the prover is required to be efficient for correctness, but soundness must hold against adversaries with unbounded running time.} 
 
Let $\pro{Setup}(\lambda)$ denote a non-interactive setup algorithm that outputs public parameters $\pp$ given a security parameter $\lambda$. Let $\Pi\bigl(\prover(w), \verifier(pp, x)\bigr)$ denote a two-party interactive protocol between $\prover$ and $\verifier$, where $\prover$ has private input $w$ and $\verifier$ has the common public input $(pp, x)$. Let $\langle \prover(w), \verifier(\pp, x) \rangle$ be a random variables that is the output of $\verifier$. All algorithms run in time $\textsf{poly}(\lambda, |pp|, |x|, |w|)$. The pair $(\pro{Setup}, \Pi)$ is called a \emph{proof of knowledge} for relation $\mathcal{R}$ if for all non-uniform adversaries $\mathcal{A}$ the following properties hold: 

\begin{itemize}
\item \underline{Perfect Completeness:} for all $(x,w) \in \mathcal{R}$
\begin{small}
\[
\Pr \left[
         \ \langle \prover(w), \verifier(\crs, x) \rangle = 1 \\
:
\begin{array}{c}
             \crs \leftarrow \pro{Setup}(\lambda) \\
\end{array} 
\right]  = 1 
 \]
 \end{small}
\item \underline{$\delta$-Knowledge Soundness:}
There exists a polynomial $\poly$ and a probabilistic oracle machine $\mathcal{E}$ called the \emph{extractor} that is given oracle access to an adversarial interactive prover algorithm $\mathcal{A}$ and public inputs $\mathsf{x} = (\crs, x)$ such that for every $x \in \mathcal{L}_R$ the following holds: if
$$\mathbb{P}\left[\langle \mathcal{A}(\crs, x), \verifier(\crs, x) \rangle = 1  : \crs \gets \setup(\lambda) \right] = \epsilon(\lambda, x)$$
 then $\mathcal{E}^\mathcal{A}(\mathsf{x})$ with oracle access to $\mathcal{A}$ runs in time $\frac{\mathsf{poly}(|\mathsf{x}|)}{\epsilon(\lambda, x)}$ and outputs $w$ such that $(x, w) \in R$ with probability at least $1 - \frac{\delta(|\mathsf{x}|)}{\epsilon(\lambda, x)}$. 
\end{itemize} 
An interactive proof is ``knowledge sound", or called a ``proof of knowledge", if it satisfies $\delta$-knowledge soundness for a negligible function $\delta:\mathbb{N} \rightarrow \mathbb{R}$, also known as the knowledge error. 
\end{definition} 
\begin{remark} Note that this definition places no restriction on the runtime of the adversary, however, it does not guarantee extraction from an adversary that succeeds with sufficiently small $\epsilon(x)$ such that $\epsilon(x) \leq  \delta(\lambda, |x|)$. For $\mathcal{R}$ in NP, this definition of knowledge soundness implies the alternative formulation of Bellare and Goldreich~\cite{C:BelGol92}, which says that the protocol has knowledge error $\delta(|x|)$ if there exists an extractor that succeeds in expected time $\frac{\textsf{poly}(|x|)}{\epsilon(x) - \delta(|x|)}$. An extractor which succeeds with probability $p = 1 - \frac{\delta(|x|)}{\epsilon(x)}$ in $t = \frac{\mathsf{poly}(|x|)}{\epsilon(x)}$ steps can run repeatedly (for $t$ steps per iteration) on fresh randomness until it obtains a witness for the relation, which it can verify efficiently. It will succeed in an expected $\frac{t}{p} =  \frac{\textsf{poly}(|x|)}{\epsilon(x) - \delta(|x|)}$ steps. Finally, this has been shown to imply another equivalent formulation which requires the extractor to run in $O(\textsf{poly}(|x|))$ steps and succeed with probability $\epsilon(x) - \delta(|x|)$.  
\end{remark}
 %As long as there exists a polynomial $p$ such that $\epsilon \cdot (1 - \frac{1}{p(\lambda)}) \geq \delta(\lambda)$ then the extractor succeeds with probability $1/p(\lambda)$ and thus can be repeated $\poly$ number of times to amplify the success probability. Informally, if a protocol is knowledge sound according to this definition, then any adversarial prover who does not know a witness succeeds with probability at most $O(\sqrt[c]{\delta(\lambda)})$.
 \fi 

\paragraph{Interactive arguments} Knowledge soundness holds against unbounded provers. The DARK protocol does not satisfy knowledge soundness because it relies on the computational binding property of cryptographic commitments. Interactive proofs that are only secure against computationally bounded adversaries are called \emph{interactive arguments}. Adapting Definition~\ref{def:proof} for arguments is more subtle than simply restricting the runtime of the adversary. The issue comes from the fact that the knowledge soundness definition quantifies the success of the extractor over all inputs $x$. For example, there could exist an input $x$ that encodes the factorization of an RSA modulus which allows the adversarial prover to break the binding property of commitments that are based on the difficulty of factoring. For this input, the adversarial prover could succeed while the extractor would fail. This particular problem is fixed by requiring the adversary to generate the input $x$. If the trapdoor is exponentially hard to compute the polynomial time adversary will not be able to embed the trapdoor in $x$ with non-negligible probability.  (See Damg\r{a}rd and Fujisaki~\cite{AC:DamFuj02} for a broader discussion of these issues).


%The standard definition of \emph{proofs of knowledge} (PoK) by Bellare and Goldreich~\cite{C:BelGol92} is based on the existence of an extractor machine $E$ that has oracle access to a malicious prover $P^*$, and if $P^*$ would cause the verifier to accept on input $X$ with high probability then $E$ outputs $w$ such that $(X, w) \in \mathcal{R}$ (with overwhelming probability). $E$ runs in expected polynomial time. This definition quantifies the success of $E$ over all inputs $x$, which unfortunately is problematic in the case of interactive  \emph{arguments}.

%To illustrate one issue, if the interactive argument relies on a \emph{structured reference string} (SRS) setup with secret trapdoor information (e.g. the factorization of an RSA modulus) then one of the inputs $x^*$ could leak the trapdoor to the prover. Any extractor should clearly fail on input $x^*$ while $P^*$ may succeed, hence the definition cannot be satisfied. This particular problem is fixed by requiring the adversary $P^*$ to generate the input $x$. If the trapdoor is exponentially hard to compute the polynomial time adversary will not be able to embed the trapdoor in $x$ except with negligible probability. (See Damg\r{a}rd and Fujisaki~\cite{AC:DamFuj02} for a broader discussion of these issues).

\paragraph{Witness-extended emulation} A property called witness-extended emulation~\cite{C:Lindell01} strengthens the knowledge-soundness definition so that the extractor outputs not only a witness but also a simulated transcript of the messages between the prover and verifier. This property is helpful for composability. In particular, if the interactive proof is used as a subprotocol within a larger protocol, it may be necessary in the security analysis to construct a simulator that needs to both obtain the adversary's witness as well as simulate its view in the subprotocol. Fortunately, Lindell~\cite{C:Lindell01} proved that every knowledge sound protocol also satisfies witness-extended emulation. Groth and Ishai~\cite{EC:GroIsh08} further adapt the definition of witness-extended emulation for interactive arguments with setup (i.e., SRS model). This is the definition we will use in the present work. \benedikt{but not for the NI version}

Before presenting the definition we will introduce some useful notations. In the SRS model, there is a setup algorithm $\setup$ that generates public parameters $\crs$ that are common inputs to the prover $\prover$ and verifier $\verifier$. The setup, which may or may not require a trusted party to sample trapdoor secrets, typically generates these parameters based on a security parameter $\lambda$ necessary for computational security. Without loss of generality, the length of $\crs \gets \setup(\lambda)$ is at least $\lambda$ bits. For any prover algorithm $\prover^*$ interacting with a verifier algorithm $\verifier$, which may deviate arbitrarily from the honest prover algorithm $\prover$, let $\textsf{Record}(\prover^*, \params, x, \st)$ denote the message transcript between $\prover^*$ and $\verifier$ on shared inputs $x$ and $\params$ and initial prover state $\st$. For $\tr \gets \textsf{Record}(\prover^*, \params, x, \st)$ let $V_{\textsf{check}}(\tr)$ denote the verifier's decision algorithm to accept or reject the transcript. Furthermore, let $\mathcal{E}^{\textsf{Record}(\prover^*, \params, x, \st)}$ denote a machine $\mathcal{E}$ with a transcript oracle for this interaction that can be rewound to any round and run again on fresh verifier randomness.

\begin{definition}[Witness-extended emulation~\cite{EC:GroIsh08,C:Lindell01}]\label{def:wee} 
An interactive proof in the SRS model $\Pi = (\textsf{Setup}, \prover, \verifier)$ satisfies witness-extended emulation for relation $\mathcal{R}$ if for every deterministic polynomial time $\prover^*$ there exists an expected polynomial time emulator $\mathcal{E}$ such that for any non-uniform\footnote{A non-uniform adversary may run a different algorithm for each input length.} adversary $\mathcal{A}$ and distinguisher $\mathcal{D}$ that runs in time $\poly$ the following condition holds: 
\begin{small}
\[
\Pr \left[
\mathcal{D}(\textsf{tr}) = 1
:
\begin{array}{c}
             \params \leftarrow \textsf{Setup}(1^\lambda) \\
             (x, \st) \leftarrow \mathcal{A}(\params) \\
             \tr \leftarrow \textsf{Record}(\prover^*, \params, x, \st)
\end{array} 
\right] \approx_\lambda
\]
\[
\Pr \left[
\begin{array}{c} 
\mathcal{D}(\textsf{tr}) = 1 \ \text{and} \\ 
V_{\textsf{check}}(\tr) = 1 \Rightarrow \ (x, w) \in \mathcal{R}
\end{array} 
:
\begin{array}{c}
             \params \leftarrow \textsf{Setup}(1^\lambda) \\
             (x, \st) \leftarrow \mathcal{A}(\params) \\
(\textsf{tr}, w) \leftarrow \mathcal{E}^{\textsf{Record}(\prover^*, \params, x, \st)}(\params, x)
\end{array}
\right]
\]
\end{small}
where $X \approx_\lambda Y$ denotes that $|X - Y| \leq \negl$. 
\end{definition}

\begin{lemma}[Lindell~\cite{C:Lindell01}]\label{lem:wee}
	Any proof of knowledge for relation $\mathcal{R}$ also satisfies witness-extended emulation for $\mathcal{R}$.  
\end{lemma}

\begin{lemma}\label{lem:weecommit}

Let $\mathcal{R}$ denote any NP relation. Given a commitment scheme $\textsf{com} = (\setup, \commit, \open)$, for any $\crs \gets \setup(\lambda)$ let $\mathcal{R}'(\crs)$ denote the relation: 
$$\mathcal{R'}(\crs) = \{(\mathsf{x}, \mathsf{w}): \mathcal{R}(\mathsf{x}, \mathsf{w}) = 1 \  \vee \ \left[ \mathsf{w} = (C, \sigma_1, \sigma_2) \ \wedge \ \sigma_1 \neq \sigma_2 \ \wedge \ \open(\crs, C, \sigma_1) = \open(\crs, C, \sigma_2) = 1 \right]   \} $$
Let $\Pi(\crs)$ denote the interactive protocol between $\prover$ and $\verifier$ parameterized by the setup parameter $\crs$. If for all $\crs \gets  \setup(\lambda)$ the protocol $\Pi(\crs)$ is a proof of knowledge (Definition~\ref{def:proof}) for $\mathcal{R}'(\crs)$ then the tuple $(\setup, \prover, \verifier)$ as an interactive proof with setup satisfies witness-extended emulation (Definition~\ref{def:wee}) for $\mathcal{R}$. 	
\end{lemma}
\ben{What's the WE error in terms of the knowledge error?} 
\benedikt{I think attema gives a precise one}

\begin{proof}
By Lemma~\ref{lem:wee} a knowledge sound interactive proof for $\mathcal{R}'(\crs)$ also satisfies witness-extended emulation for $\mathcal{R}'(\crs)$. It remains to show that this implies witness-extended emulation for $\mathcal{R}$. It suffices to show that: 

\begin{small}
\[
\Pr \left[
\begin{array}{c} 
\mathcal{D}(\textsf{tr}) = 1 \ \text{and} \\ 
V_{\textsf{check}}(\tr) = 1 \Rightarrow \ (x, w) \in \mathcal{R}
\end{array} 
:
\begin{array}{c}
             \params \leftarrow \textsf{Setup}(\lambda) \\
             (x, \st) \leftarrow \mathcal{A}(\params) \\
(\textsf{tr}, w) \leftarrow \mathcal{E}^{\textsf{Record}(\prover^*, \params, x, \st)}(\params, x)
\end{array}
\right] \approx_\lambda
\]
\[
\Pr \left[
\begin{array}{c} 
\mathcal{D}(\textsf{tr}) = 1 \ \text{and} \\ 
V_{\textsf{check}}(\tr) \Rightarrow \ (x, w) \in \mathcal{R}'(\crs)
\end{array} 
:
\begin{array}{c}
             \params \leftarrow \textsf{Setup}(\lambda) \\
             (x, \st) \leftarrow \mathcal{A}(\params) \\
(\textsf{tr}, w) \leftarrow \mathcal{E}^{\textsf{Record}(\prover^*, \params, x, \st)}(\params, x)
\end{array}
\right]
\]
\end{small}

The difference between these two probabilities is bounded by the probability, over the distribution on the right side of the equation, that $(\mathsf{x}, \mathsf{w}) \in \mathcal{R}'(\crs)$ but $(\mathsf{x}, \mathsf{w}) \not \in \mathcal{R}$. This event implies that $\mathsf{w}$ encodes a break to the commitment scheme with parameters $\crs$. Since $\mathcal{A}$, $P^*$, $\textsf{Setup}$ and $\mathcal{E}$ all run in time $\poly$ this occurs with probability at most $\negl$ over randomly sampled $\crs \gets \setup(\lambda)$ by the computational binding property of the commitment scheme. More precisely, supposing that the difference between these two probabilities is $\epsilon(\lambda)$, then we can use $\mathcal{A}$, $P^*$, and $\mathcal{E}$ to construct an algorithm $\mathcal{A}'$ which on input $\crs \gets \setup(\lambda)$ simulates $(x, \st) \gets \mathcal{A}(\crs)$ and $(\tr, w) \gets \mathcal{E}^{\textsf{Record}(\prover^*, \params, x, \st)}(\params, x)$ returning $w$ such that: 
\[
\Pr \left[
w = (C, \sigma_1, \sigma_2) \ \wedge \ \sigma_1 \neq \sigma_2 \ \wedge \ \verify_\crs(C, \sigma_1) = \verify_\crs(C, \sigma_2) = 1
:
\begin{array}{c}
             \params \leftarrow \textsf{Setup}(\lambda) \\
             w \gets \mathcal{A}'(\crs)
\end{array}
\right] = \epsilon(\lambda) 
\]

If $\epsilon(\lambda)$ is non-negligible this contradicts the binding property of the commitment scheme.  
\end{proof} 


\paragraph{Zero knowledge} We recall the definition of \emph{honest verifier zero-knowledge} (HVZK) for interactive proofs. HVZK only considers simulating the view of a verifier that follows the protocol honestly. The Fiat-Shamir transform compiles public-coin proofs that have HVZK into non-interactive proofs that have statistical zero-knowledge (for malicious verifiers). 
%\ben{TODO: cite appropriate works, Bellare-Rogaway, more recent for more than constant round} 

\begin{definition}[HVZK for interactive arguments]
\label{def:hvzk}
Let $\textsf{View}_{\langle \prover(x, w), \verifier(x) \rangle}$ denote the view of the verifier in an interactive protocol on common input $x$ and prover witness input $w$. The interactive protocol has $\delta$-statistical honest verifier zero-knowledge if there exists a probabilistic polynomial time algorithm $\mathcal{S}$ such that for every $(x, w) \in \mathcal{R}$, the distribution $\mathcal{S}(x)$ is $\delta$-close to $\textsf{View}_{\langle \prover(x, w), \verifier(x) \rangle}$ (as distributions over the randomness of $\prover$ and $\verifier$).
\end{definition}

\if 0 
Consider any deterministic adversarial interactive prover algorithm $P^*$. For any $\st$, define $\mathcal{A}_{\st}$, which has hardcoded $\st$ and runs $P^*$ with initial private state $\st$. Since the protocol is knowledge sound for $\mathcal{R}'$ there exists a constant $c \in \mathbb{N}$ and an extractor $\mathsf{Ext}$ with the following property. Consider any $(\mathsf{x}, \st)$ and suppose that: 
$$\Pr \left[
\begin{array}{c} 
D_V(\tr) = 1 
\end{array} 
:
\begin{array}{c}
\textsf{tr} \leftarrow \textsf{Record}(\prover^*, \params, \mathsf{x}, \st)
\end{array}
\right] = \epsilon(\mathsf{x}, \st)
 $$ 
 
Then $\mathsf{Ext}^{\mathcal{A}_\st}(\params, \mathsf{x})$ runs in time $\textsf{poly}(\frac{1}{\epsilon(\mathsf{x}, \st)}, |\mathsf{x}|, \lambda)$ and returns a witness $\mathsf{w}$ such that $(\mathsf{x}, \mathsf{w}) \in \mathcal{R}'$ with probability at least $1 - \frac{1}{\epsilon(\mathsf{x}, \st)^c} \cdot \negl$. Furthermore, for any $\delta \in (0,1)$:

$$\Pr \left[
\begin{array}{c} 
D_V(\tr) = 1  \ \wedge \epsilon(\mathsf{x}, \st) \leq \delta
\end{array} 
:
\begin{array}{c}
\params \leftarrow \setup(\lambda) \\ 
(\mathsf{x}, \st) \leftarrow \mathcal{A}(\params) \\ 
\textsf{tr} \leftarrow \textsf{Record}(\prover^*, \params, \mathsf{x}, \st)
\end{array}
\right] \leq  \delta
 $$  
 
 This implies that $\epsilon(\mathsf{x}, \st) > 1/\poly$ with probability greater that $1/\poly$ over $\params \leftarrow \setup(\lambda)$ and $(\mathsf{x}, \st ) \leftarrow \mathcal{A}(\params)$.  

%If $\frac{1}{\epsilon(\mathsf{x}, \st)}$ is polynomial in $\lambda$ and also then the witness returned 
\end{proof}
\fi 


\section{Almost-Special-Soundness Theorems} 



\begin{definition}[Almost-Special-Soundness]\label{def:darkspecialsoundness} A $\mu$-round public-coin interactive proof for a relation $\mathcal{R}$ with challenge space of size $2^\lambda$ is \textbf{$(k^{(\mu)}, \delta(\cdot), \com, \phi)$-almost-special-sound} if it satisfies the following conditions with respect to some commitment scheme $\com = (\setup,\commit, \open)$ with message space $\mathcal{M}$ and opening space $\mathcal{W}$, a pair of predicates $\phi = (\phi_a, \phi_b)$ where $\phi_a, \phi_b:[\mu] \times \mathcal{M}  \rightarrow \{0,1\}$, and a negligible function $\delta: \mathbb{N} \rightarrow \mathbb{R}$:

\begin{enumerate} 
\item The setup for the interactive proof includes generation of the public parameters for the commitment scheme $\crs \gets \textsf{com}.\setup(\lambda)$.  
\item  In any accepting transcript, the prover's $i$th round message for $i \in [1,\mu)$ is a valid commitment $\mathcal{C}_i$ for the scheme $\mathsf{com}$, and the final prover message is a commitment $\mathcal{C}_\mu$ together with a valid opening $(m_\mu, o_\mu)$ such that $\textsf{com}.\open(\crs,C_\mu, m_\mu, o_\mu) = 1$ and $\phi_a(\mu, m_\mu) = 1$. 


\item  There is a $poly(\lambda)$ time algorithm $\textsf{Extract}(i, \nu, C_\nu, \textsf{openSubtree}) \rightarrow (m, o)$ where $i \in [1,\mu]$ and $\textsf{openSubtree}$ is a list of openings for the commitments on all internal nodes (excluding the root and leaves) of a $k$-ary depth $\mu - i$ subtree of a transcript tree rooted at a node $\nu$ on the $i$th level with commitment label $C_\nu$. If the challenge labels on the first two children of any node in the subtree are distinct, and the openings for all internal (non-root) nodes of the subtree satisfy predicate $\phi_a$ (i.e., for any $j > i$ and node $u$ on the $j$th level of the transcript tree that is a member of this subtree, its opening $(m_u, o_u)$ in $\textsf{openSubtree}$ satisfies $\phi_a(j, m_u)= 1$) then the algorithm returns a valid opening $(m,o)$ for $c_\nu$ such that $\phi_b(i, m) = 1$.  

\item  $\textsf{Extract}(0,x,\textsf{openTree}) \rightarrow w$ takes as inputs openings for the commitments on all nodes in an entire transcript tree satisfying predicate $\phi_a$ (same condition as above for subtrees) and returns a witness $\mathsf{w}$ for the public input $\mathsf{x}$ such that $\mathcal{R}(\mathsf{x},\mathsf{w})=1$. 

\item  $\textsf{Extend}(i, m, \alpha_1,..,\alpha_{\mu-i})$ is a deterministic $\poly$-time algorithm that is given an index $i \in [\mu-1]$, a message $m$ in the message space of the commitment scheme $\textsf{com}$, $\mu-i$ challenges from $\mathcal{X}$, and outputs $\mu-i$ messages $m'_1,...,m'_{\mu-i}$ in the message space of the commitment scheme. 
\item For any $i \in [\mu-1]$ and $m$ where $\phi_a(i,m) = 0$, the probability over $\alpha_i,...,\alpha_\mu$ sampled uniformly i.i.d. from $\mathcal{X}$ that the last message $m'_{\mu-i}$ in the list returned by $\textsf{Extend}(i, m)$ satisfies $\phi_a(\mu, m'_{\mu-i}) = 1$ is bounded by $\delta(\lambda)$.   

\item $\textsf{Break}(i, m, \alpha_1,...,\alpha_\mu, C_0,...,C_\mu, (m_i, o_i),...,(m_{\mu}, o_{\mu}))$ first runs $\textsf{Extend}(i, m, \alpha_i,..,\alpha_{\mu})$, which returns messages $m'_1,...,m'_{\mu-i}$. If  either $\phi_b(i, m_i) = 0$ or $\forall_j$ $m'_j = m_{i + j -1}$ then it outputs $\bot$. Otherwise it outputs an attempted opening $(m', o')$ of $C_j$ for some index $j \geq i$ where $m' \neq m_j$. %\benedikt{Change break to output bot if phib is 0.}


%\item For any $i \in [\mu-1]$ and algorithm $\mathcal{A}$ that runs in time at most $t_\mathcal{A} \in O(\poly)$ to generate a valid (accepting) transcript with commitments $(C_0,...,C_\mu)$ and openings $((m_{i+1},o_{i+1}),...,(m_\mu, o_\mu))$ to the last $\mu-i$ commitments, where $\phi_b(j, m_j, o_j) = 1$ for all $j \in [i+1,\mu]$, then $\textsf{Extend}(i, m_i)$ returns $m_{i+1},...,m_{\mu}$ in time $t_E$ with overwhelming probability $1 - \delta(t_\mathcal{A} + t_E)$ over the internal randomness of $\mathcal{A}$ (and randomness of the commitment scheme setup if applicable).  

\item For any $i \in [\mu-1]$, given a valid (accepting) transcript with commitments $\mathbf{C} = (C_0,...,C_\mu)$, round challenges $\mathbf{r} = (\alpha_1,...,\alpha_{\mu})$, and openings $\mathbf{open} = ((m_{i},o_{i}),...,(m_\mu, o_\mu))$ to the last $\mu-i+1$ commitments, where $\phi_b(i, m_i) = 1$ and $\phi_a(j, m_j) = 1$ for all $j \in [i+1,\mu]$, either $\textsf{Extend}(i, m_i, \alpha_{i+1},...,\alpha_\mu)$ returns $m_{i+1},...,m_{\mu}$ or $\textsf{Break}(i, m_i, \mathbf{r}, \mathbf{C}, \mathbf{open})$ returns an opening $(m', o')$ of some $C_j$ to a conflicting message $m' \neq m_j \in \mathcal{M}$, which breaks the binding of the commitment scheme over $\mathcal{M}$.
\end{enumerate} 

\textbf{Short-hand notation:} An interactive proof is $(k^{(\mu)}, \delta)$-almost-special-sound if it is $(k^{(\mu)}, \delta, \com, \phi)$-almost-special-sound for some commitment scheme $\textsf{com}$ and some predicate pair $\phi$. We may omit $\delta$ and simply write $k^{(\mu)}$-almost-special-soundness if this holds for some negligible function $\delta: \mathbb{N} \rightarrow \mathbb{R}$. 
\end{definition} 

\begin{remark} Any special sound protocol satisfies almost-special-soundness as 3) essentially captures the special soundness definition. More precisely a $k^{(\mu)}$-special sound satisfies $k^{(\mu)}$-almost-special-soundness by setting the commitment scheme to be trivial (i.e., identity function) and the $i$th round commitment $C_i$ to the prover's $i$th round message and setting the predicates $\phi_a=1, \phi_b=0$ to be trivial as well (i.e., always return 1 and 0 respectively). The algorithm $\textsf{Extend}$ can output an arbitrary set of messages because the condition on the algorithm is vacuously true as $\phi_a(i,m) \neq 0$ for any $(i,m)$. The algorithm $\textsf{Extract}(i, \nu, C_\nu, *)$ is trivial because $C_\nu$ is the message itself. The algorithm $\textsf{Break}$ is also trivial as $\phi_b$ is always $0$. The algorithm $\textsf{Extract}(0, x, openTree) \rightarrow w$ exists by the definition of $k^{(\mu)}$-special soundness. %\benedikt{For break do nothing and for phib it needs to ouput 0 otherwise this doesn't work.}
\end{remark}



\begin{theorem}\label{thm:DARKExtractor} If a $\mu$-round interactive proof for a relation $\mathcal{R}$ with $\lambda$-bit challenges, $\mu \in O(\log(\lambda + |\mathsf{x}|))$, and verifier decision algorithm runtime $t_V \in \textsf{poly}(|\crs|, |\mathsf{x}|, \lambda)$ on input $\mathsf{x} \in \mathcal{L}_\mathcal{R}$ and parameters $\crs \gets \textsf{com}.\setup(\lambda)$ is $(k^{(\mu)}, \delta, \textsf{com}, \phi)$-almost-special-sound then for $\delta'(\lambda) = 2\lambda (k+1)^\mu (\mu + t_V) \cdot \max(\delta(\lambda), k \cdot 2^{-\lambda}) + 2^{-\lambda}$ it is $\delta'$-knowledge sound for the modified relation:
$$\mathcal{R'}(\crs) = \{(\mathsf{x}, \mathsf{w}): \mathcal{R}(\mathsf{x}, \mathsf{w}) = 1 \  \vee \mathsf{w} \in \mathcal{L}_\textsf{break}(\crs)\} $$
 where 
 $$\mathcal{L}_\textsf{break}(\crs) = \{ (\mathcal{C}, \sigma_1, \sigma_2) :   \sigma_1 \neq \sigma_2 \ \wedge \ \open(\crs,\mathcal{C}, \sigma_1) = \open(\crs,\mathcal{C}, \sigma_2) = 1    \} $$ 

\end{theorem} 
\begin{remark} $\delta'(\lambda)$ is a negligible function if $\delta(\lambda)$ is negligible, assuming $k \in O(1)$, $\mu \in O(\log(\lambda + |\mathsf{x}|))$, $t_V \in \textsf{poly}(|\mathsf{x}|, \lambda)$, and $|\mathsf{x}| \in \textsf{poly}(\lambda)$. 	
\end{remark}

By Lemma~\ref{lem:weecommit}, this theorem has the following corollary:
\begin{corollary}
\label{cor:dsstowee}
An interactive proof with $\lambda$-bit challenges that is $k^{(\mu)}$-almost-special-sound for a relation $\mathcal{R}$ and has at most $\mu \in O(\log(\lambda + |\mathsf{x}|))$ rounds on any instance $\mathsf{x} \in \mathcal{L}_\mathcal{R}$ has witness-extended emulation for $\mathcal{R}$.  
\end{corollary}



\begin{proof} 
Suppose we have a protocol that is $(k^{(\mu)}, \delta)$-almost-special-sound with challenge space $\mathcal{X}$ of size $2^\lambda$ for some negligible function $\delta: \mathbb{N} \rightarrow \mathbb{R}$. We will make use of algorithms $\textsf{Extract}$, $\textsf{Extend}$, and $\textsf{Break}$ and their properties that are guaranteed to exist by the definition of almost-special-soundness (Definition~\ref{def:darkspecialsoundness}). 

For any node $\nu$ of a $(k+1)$-ary transcript tree let $S^*_\nu$ denote the \emph{left} $k$-ary subtree rooted at $\nu$ defined by a breadth first search from $\nu$ that visits only the first $k$ children of each node reached (i.e., prunes the rightmost branch from each node of the complete $(k+1)$-ary subtree $S_\nu$).

In Definition~\ref{def:TreeExtract}, we define an algorithm $\textsf{TreeExtract}(\ell_\nu, \nu, \mathcal{C}_\nu, L_{S_\nu})$ that operates on a labeled subtree of a $(k+1)$-ary transcript tree that has depth $\mu$,  where $\ell_\nu$ is the level of $\nu$, $\mathcal{C}_\nu = L(\nu)_1$ is the commitment label on $\nu$ and $L_{S_\nu}$ is a labeling of the $(k+1)$-ary subtree $S_\nu$ rooted at $\nu$. If $\textsf{TreeExtract}(\ell_\nu, \nu, \mathcal{C}_\nu, L_{S_\nu})$ succeeds it returns $\textsf{openSubtree}$, which contains openings of all the commitment labels $L$ assigned to nodes in $S_\nu$ including the label $\mathcal{C}_\nu$ on node $\nu$. Otherwise it returns $\bot$. The \textsf{TreeExtract} algorithm is not guaranteed to succeed. In particular, the internal calls to $\textsf{Extract}$ are only guaranteed to succeed when the openings of subtrees satisfy predicate $\phi_a$ and the challenge labels are distinct within the pruned subtrees $S^*_\nu$. Definition~\ref{def:TreeExtract} also defines $\textsf{TreeExtract}^*(\ell_\nu, \mathcal{C}_\nu, L_{S^*_\nu})$, an algorithm that only extracts openings of the commitments in $L_{S^*_\nu}$ and returns an opening of $C_\nu$. This runs similarly to $\textsf{TreeExtract}$, but it is only a function of nodes present in the left $k$-ary subtree $S^*_\nu$. While it is possible that $\textsf{TreeExtract}$ fails and $\textsf{TreeExtract}^*$ succeeds, they will always output the same opening of $C_\nu$ in the event that both succeed.

Let $\textsf{size}(k, \mu) = \frac{k^{\mu+1}-1}{k-1}$, which is the number of nodes is a $k$-ary depth $\mu$ tree. Given any $\mu$-round protocol that satisfies $(k^{(\mu)}, \delta)$-almost-special-soundness, setting $N = \textsf{size}(k+1, \mu)$ we will define a collection of predicates $\{\pi_\nu: \nu \in [1,N]\}$ for the nodes of a $k$-ary transcript tree with post-order labeling $L$, such that each $\pi_\nu$ is a function of the partial labeling $L_{\nu^*}$ and a $\mu - \ell_\nu$-length challenge vector $\mathbf{r} \in \mathcal{X}^{\mu - \ell_\nu}$, where $\ell_\nu$ is the level of node $\nu$ in the tree. Recall that $\nu^* < \nu$ is the node of highest index smaller than $\nu$ that is not a member of the subtree of $\nu$, and $L_{\nu^*}$ are the labels of all nodes numbered $[1, \nu^*]$. Let $\omega$ denote the parent node of $\nu$. The predicate $\pi_\nu(L_{\nu^*}, \mathbf{r})$ is defined as follows: 
\begin{itemize} 
\item If $\nu$ has no left-sibling, then $\pi_\nu$ always returns $1$. 
\item If $\nu$ has $0 < i < k$ left-siblings (i.e., it is neither the first nor last child) then $\pi_\nu(L_{\nu^*}, \mathbf{r}) = 1$ iff the challenge label $L(\nu)_0$ assigned to $\nu$ is distinct from the challenge labels assigned to its $i$ left-siblings. Note that if $\nu'$ is a left-sibling of $\nu$ then $\nu' \in [1, \nu^*]$ so $L(\nu')$ is included in the input $L_{\nu^*}$ to $\pi_\nu$. 
\item If $\nu$ has no right-sibling (i.e., is rightmost child) then let $\mathcal{C}_\omega = L(\omega)_1$ denote the commitment label on $\omega$, let $(m_\omega, o_\omega)$ denote the opening of $\mathcal{C}_\omega$ returned by $\textsf{TreeExtract}^*(\ell_\omega, \omega, \mathcal{C}_\omega, L_{S^*_\omega})$ if successful, let $m'$ denote the last message in the output list of $\textsf{Extend}(\ell_\omega, m_\omega,\mathbf{r})$ and finally: 

 $$\pi_\nu(L_{\nu^*}, \mathbf{r}) = 
 \begin{cases} 1 \quad\quad \text{ if }  \textsf{TreeExtract}^*(\ell_\omega, \omega, \mathcal{C}_\omega, L_{S^*_\omega}) = \bot \\ 
 1 \quad \quad \text{ if } \phi_a(\ell_\omega, m_\omega) = 1\\
 1 \quad \quad \text{ if } \phi_a(\ell_\omega, m_\omega) = 0 \wedge \phi_a(\mu, m') = 0 \\ 
0\text{ otherwise} 
\end{cases} $$ 


\end{itemize}
As remarked above, while $\textsf{TreeExtract}$ operates on the entire $(k+1)$-ary subtree of labels rooted at $\omega$, the algorithm $\textsf{TreeExtract}^*$ takes as input only the labeling of the right $k$-ary subtree $S^*_\omega$ and $L_{S^*_\omega} \subseteq L_{\nu^*}$. 
By the definition of $(k^{(\mu)}, \delta)$-almost-special-soundness (Definition~\ref{def:darkspecialsoundness}, pt. 5), for any $\nu \in [0,N)$ that has no right-sibling and any $L_{\nu^*}$: 
$$\mathbb{P}_{\mathbf{r} \leftarrow \mathcal{X}^{\mu - \ell_\nu}}[ \pi_v(L_{v^*}, \mathbf{r}) = 1 ] \geq 1 - \delta(\lambda)$$  

If $\nu$ has $0 < i < k$ left-siblings then by a union bound: 
$$\mathbb{P}_{\mathbf{r} \leftarrow \mathcal{X}^{\mu - \ell_\nu}}[ \pi_v(L_{v^*}, \mathbf{r}) = 1 ] \geq 1 - \frac{i}{2^\lambda} $$ 

Let $\textsf{lpath}(\nu)_0$ denote the challenge labels $L(\cdot)_0$ along the leftmost branch from $\nu$ to a leaf starting with the label $L(\nu)_0$ on $\nu$. By Lemma~\ref{lem:ppfl} (Path Predicate Forking Lemma) there is an algorithm $\textsf{Tree}^\mathcal{A}(\mathsf{z})$ that, given a security parameter $\lambda \in \mathbb{N}$, an input $\mathsf{x} \in \mathcal{L}_\mathcal{R}$, and oracle access to an adversarial prover $\mathcal{A}$ that causes $V$ to accept on input $\mathsf{x}$ with probability $\epsilon$, runs in time at most $t = 2\lambda \cdot \frac{(k+1)^\mu}{\epsilon} \cdot (\mu + t_V)$, where $t_V$ is the worst-case running time of verifier's decision algorithm, and returns with probability at least $1 - t \cdot \max(\delta(\lambda), \frac{k}{2^\lambda}) - 2^{-\lambda}$ a $(k+1)$-ary transcript tree with post-order labelling $L:[1,N] \rightarrow \mathcal{X}\times \mathcal{M}$ such that $\pi_v(L_{v^*}, L(\textsf{lpath}_v)_0) = 1$ for all $v \in [1,N]$. 


 In particular, $L$ defines a $(k+1)$-ary transcript tree with the properties: 
\begin{enumerate}
\item The challenge labels on the first $k$ children of any node are distinct, i.e., if $\omega$ has children $\nu_1,...,\nu_{k+1}$ ordered from left-to-right, then for any $i, j \in [1, k]$ if $i \neq j$ then $L_0(\nu_i) \neq L_0(\nu_j)$. 
\item  If $\nu$ is the $(k+1)$th child of $\omega$ and running $\textsf{TreeExtract}(\ell_\omega, \omega, \mathcal{C}_\omega, L_{S^*_\omega})$ at level $\ell_\omega$ returns an opening of $\mathcal{C}_\omega$ to $m_\omega$ such that $\phi_a(\ell_\omega, m_\omega) \neq 1$, then the final output of $\textsf{Extend}(\ell_\omega, m_\omega, \textsf{lpath}(\nu)_0)$ is a message $m'$ such that $\phi_a(\mu, m') \neq 1$. 
\end{enumerate} 

By Lemma~\ref{lem:DARKExtractor} there is a deterministic extraction algorithm that takes any $L$ with the above properties and computes a witness $\mathsf{w}$ such that $(\mathsf{x}, \mathsf{w}) \in \mathcal{R}'$. 

\medskip 

In conclusion, for any adversarial prover that succeeds on input $x$ with probability $\epsilon(x)$, there is a probabilistic extractor that runs in time at most $t = 2\lambda \frac{(k+1)^\mu}{\epsilon(x)} (\mu + t_V)$ and with probability at least $1 - t \cdot \max(\delta(\lambda), \frac{k}{2^\lambda}) - 2^{-\lambda}$ returns a witness for $\mathcal{R}'$. Since $t \in \frac{\textsf{poly}(|x|, \lambda)}{\epsilon(x)}$ assuming $\mu \in O(\log(\lambda + |x|))$ and $t_V \in \textsf{poly}(|x|, \lambda)$, this satisfies the definition of $\delta'$-knowledge soundness with $\delta'(\lambda) = 2\lambda (k+1)^\mu (\mu + t_V) \cdot \max(\delta(\lambda), k \cdot 2^{-\lambda}) + 2^{-\lambda}$, which is a negligible function of $\lambda$ as long as $\delta(\lambda)$ is negligible. 


\end{proof} 

\begin{definition}[Tree Extractor]\label{def:TreeExtract}

We define an algorithm $\textsf{TreeExtract}(k, \ell, \nu, \mathcal{C}_\nu, L_{S_\nu})$ that operates on a labeled subtree of a $(k+1)$-ary transcript tree that has depth $\mu$,  where $\ell_\nu$ is the level of $\nu$, $\mathcal{C}_\nu = L(\nu)_1$ is the commitment label on $\nu$ and $L_{S_\nu}$ is a labeling of the $(k+1)$-ary subtree $S_\nu$ rooted at $\nu$. If $\textsf{TreeExtract}(\ell_\nu, \nu, \mathcal{C}_\nu, L_{S_\nu})$ succeeds it returns $\textsf{openSubtree}$, which contains openings of all the commitment labels $L$ assigned to nodes in $S_\nu$ including the label $\mathcal{C}_\nu$ on node $\nu$. Otherwise it returns $\bot$. The algorithms runs as follows: 
\begin{itemize}  
\item For all leaf nodes $\nu$, return the opening of $\mathcal{C}_\nu$, which is included in the label on $\nu$. \
\item For each node $\omega \in S_{\nu}$ on the second to last level with label $\mathcal{C}_\omega = L(\omega)_1$, set $\textsf{openLeaves}$ to include the first $k$ opened leaves of $\omega$, and run $\textsf{Extract}(\mu - 1, \omega, \mathcal{C}_\omega, \textsf{openLeaves})$ to get an opening of $\mathcal{C}_\omega$.
\item Continue iteratively: once openings for all commitment labels of all subtrees rooted at the $i$th level have been computed, for each node $\omega$ on the $(i+1)$st level with label $\mathcal{C}_\omega = L(\omega)_1$ run $\textsf{Extract}(i, \omega, \mathcal{C}_\omega, \textsf{openSubtree}^*_\omega)$ on the commitment label openings $\textsf{openSubtree}^*_\omega$ of the left $k$-ary subtree $S^*_\omega$ (excluding node $\omega$), which were computed in prior iterations. 
\end{itemize}
Finally, $\textsf{TreeExtract}^*(\ell_\nu, \mathcal{C}_\nu, L_{S^*_\nu})$ denotes the algorithm that only extracts openings of the commitments in $L_{S^*_\nu}$ and returns an opening of $\mathcal{C}_\nu$. This runs exactly like $\textsf{TreeExtract}$ except that it only iterates over nodes that are present in the left $k$-ary subtree $S^*_\nu$. 
\end{definition}

The \textsf{TreeExtract} algorithm is not guaranteed to succeed. In particular, the internal calls to $\textsf{Extract}$ are only guaranteed to succeed when the openings of subtrees satisfy predicate $\phi_a$ and the challenge labels are distinct within the pruned subtrees $S^*_\nu$. By convention, if any internal step fails then \textsf{TreeExtract} outputs $\bot$. While it is possible that $\textsf{TreeExtract}$ $\mathsf{fail}$s and $\textsf{TreeExtract}^*$ succeeds, it is easy to see that they output the same opening of $C_\nu$ assuming both succeed. Furthermore, while $\textsf{TreeExtract}$ operates on $(k+1)$-ary transcript tree, the internal calls to $\textsf{Extract}$ run on $k$-ary transcript trees because it is defined for a protocol that is $(k^{(\mu)}, \delta)$-almost-special-sound. The reason we always pass the labeling/opening of the left $k$-ary subtree (as opposed to an arbitrary $k$-ary subtree) to $\textsf{Extract}$ is to ensure that the opening of $\mathcal{C}_\nu$ included in the output of $\textsf{TreeExtract}(\ell_\nu, \mathcal{C}_\nu, L_{S_\nu})$ is a function of only the labels on the left $k$-ary subtree $S^*_\nu$, and in particular is computed independently from any of the labels in the (rightmost) subtree rooted at the $(k+1)$th (rightmost) child of $\nu$. This fact is used in the proof of Theorem~\ref{thm:DARKExtractor}.

\begin{definition}[Predicate Special Soundness]
	Let $\rho$ denote any binary predicate that takes as input any $k$-ary $\mu$-depth transcript tree. A $\mu$-round public coin interactive proof for a relation $\mathcal{R}$ with $\lambda$-bit challenges is \textbf{$(k^{(\mu)}, \rho)$-special sound} if there exists a deterministic extraction algorithm $\mathcal{E}$ that takes as input an instance $\mathsf{x} \in \mathcal{L}_\mathcal{R}$, any $k$-ary forking transcript tree rooted at $\mathsf{x}$ with labelling $L$ such that $\rho(L) = 1$, and returns a witness $\mathsf{w}$ such that $(\mathsf{x}, \mathsf{w}) \in \mathcal{R}$ in time $\textsf{poly}(\lambda, k^\mu)$. 
\end{definition}

Setting $\rho = 1$, i.e. the trivial predicate that is always true, recovers the standard definition of $k^{(\mu)}$-special soundness. Recall that we defined a \emph{forking} transcript tree (Section~\ref{sec:IPtrees}) as a transcript tree in which the challenge labels on edges that share the same parent node are distinct.\footnote{We could have defined predicate special soundness in an even more general way such that the forking property of the tree is not required, yet can be encapsulated in the predicate. However, this would not be useful for our present work and less convenient for notational purposes.} 

\begin{lemma} \label{lem:DARKExtractor}
Let $\Pi(\crs)$ denote a $(k^{(\mu)}, \delta, \textsf{com}, \phi)$-almost-special-sound protocol for a relation $\mathcal{R}$ and any $\delta \in [0,1]$, parametrized by $\crs \gets \textsf{com}.\setup(\lambda)$. Define the binary predicate $\rho$ as a function of a $(k+1)$-ary $\mu$-depth forking transcript tree given by labelling $L$, which uses the algorithms $\textsf{TreeExtract}$ from Definition~\ref{def:TreeExtract} and $\textsf{Extend}$ from Definition~\ref{def:darkspecialsoundness} and returns $1$ iff the following condition holds: 

\begin{quote} For any node $\omega$ with $(k+1)$st child $\nu$, if the result of running $\textsf{TreeExtract}(\ell_\omega, \omega, \mathcal{C}_\omega, L_{S^*_\omega})$ at level $\ell_\omega$ returns an opening of $\mathcal{C}_\omega$ to $m_\omega$ such that $\phi_a(\ell_\omega, m_\omega) \neq 1$, then the final output of $\textsf{Extend}(\ell_\omega, m_\omega, \textsf{lpath}(\nu)_0)$ is a message $m'$ such that $\phi_a(\mu, m') \neq 1$. 	
\end{quote}


$\Pi(\crs)$ is $((k+1)^{(\mu)}, \rho)$-special sound for the relation $\mathcal{R}'(\crs)$ defined in Theorem~\ref{thm:DARKExtractor}. 
 	
\end{lemma}
\begin{remark}
 The value of $\delta$ does not affect $((k+1)^\mu, \rho)$-special soundness. The value of $\delta$ affects the runtime of the extraction algorithm that is able to generate a transcript tree satisfying the predicate $\rho$ (in Theorem~\ref{thm:DARKExtractor}). 
\end{remark}
\begin{proof}
We will argue that, assuming the $(k+1)$-ary forking transcript tree has property $\rho$, for any $\omega \in [1,N]$, either $\textsf{TreeExtract}(\ell_\omega, \omega, \mathcal{C}_\omega, L_{S_\omega})$ returns a subtree $\textsf{openSubtree}$ of openings of the commitment labels in $L_{S_\omega}$ satisfying $\phi_a$ (i.e., each opening of a label $C_\omega$ to $m_\omega$ for a node $\omega$ on level $\ell_\omega$ satisfies $\phi_a(\ell_\omega, m_\omega) = 1$) or else there is an efficient algorithm that uses $\textsf{openSubtree}$ and $L$ to break the commitment scheme. 


\paragraph{Step 1:} Suppose that $\omega$ is a node of highest level $\ell_{\omega}$ for which this $\mathsf{fail}$s, i.e. the output of $\textsf{TreeExtract}$ satisfies $\phi_a$ for any node of higher level than $\ell_\omega$. 
This means that all the openings of internal (non-root) nodes of the subtree $L_{S_\omega}$ computed while running $\textsf{TreeExtract}$ on $\omega$ satisfy $\phi_a$. Furthermore, $L$ has the property that all labels on the first $k$ siblings are distinct. 

\paragraph{Step 2:} By the definition of almost-special-soundness and the hypothesis in \textbf{Step 1}, the algorithm $\textsf{TreeExtract}(\ell_\omega, \omega, \mathcal{C}_\omega, L_{S_\omega})$ succeeds in returning $\textsf{openSubtree}$ consisting of the openings of $L_{S_\omega}$ such that the openings of all internal (non-root) nodes satisfy $\phi_a$, and the opening $(m_\omega, o_\omega)$ of the subtree root $\omega$ satisfies $\phi_b(\ell_\omega, m_\omega) = 1$. The opening $(m_\omega, o_\omega)$ is also identical to the output of $\textsf{TreeExtract}^*(\ell_\omega, \omega, \mathcal{C}_\omega, L_{S^*_\omega})$. 

\paragraph{Step 3:}  Let $\nu$ denote the rightmost child of $\omega$. By hypothesis, if $\phi_a(\ell_\omega, m_\omega) = 0$ then the final output of $\textsf{Extend}(\ell_\omega, m_\omega, \textsf{lpath}(\nu))$ is a message $m'$ such that $\phi_a(\mu, m') = 0$. However, this implies that $m'$ must be distinct from the label $L$ assigns to the leaf node of the rightmost branch extending from $\nu$. Let $v_1,...,v_\mu$ denote the nodes along the root-to-leaf path passing through node $\omega$ and ending with its leftmost branch so that $\textsf{lpath}(\nu) = (L(v_{\ell_\nu})_0,...,L(v_\mu)_0)$. For each $i \in [1, \mu]$ let $\hat{C}_i = L(v_i)_1$ and $\mathbf{\hat{C}} = (\hat{C}_1,...,\hat{C}_\mu)$. Finally, since $\phi_b(\ell_\omega, m_\omega) = 1$ and $\textsf{openSubtree}$ contains openings $(m_{\ell_\nu}, o_{\ell_\nu}),...(m_\mu, o_\mu)$ of the commitments $\hat{C}_{\ell_\nu},...\hat{C}_\mu$ that all satisfy predicate $\phi_a(i, m_i) = 1$, if $m' \neq m_\mu$ then by the definition of almost-special-soundness this implies that $\textsf{Break}(\ell_\omega, m_\omega,  \textsf{rpath}(\nu), \mathbf{\hat{C}}, (m_{\ell_\nu}, o_{\ell_\nu}),...(m_{\mu}, o_{\mu}))$ outputs a conflicting opening of some commitment label in $\mathbf{\hat{C}}$. 




Let $\mathcal{C}_1 = L(1)_1$, the transcript tree root. The extractor runs $\textsf{TreeExtract}(0, 1, \mathcal{C}_1, L_{S_1})$, which returns $\textsf{openTree}$. If every opening in $\textsf{openTree}$ satisfies predicate $\phi_a$ then it runs $\textsf{Extract}(0, \mathsf{x}, \textsf{openTree})$ to obtain witness $\mathsf{w}$ satisfying $R(\mathsf{x}, \mathsf{w}) = 1$. Otherwise, it uses the $\textsf{Break}$ algorithm (as described in the previous step) to output conflicting openings of a commitment, which is a witness for $R'(\crs)$.
	
\end{proof}

\section{DARK is Almost-Special-Sound}
\label{appendix:darkisdark}

\subsection{Correctness}
\label{sec:darkcorrectness}
\def\thelemma{\ref{lem:correctness}}
\newtheorem*{lemmacorrectness}{Lemma \ref{lem:correctness}}
\begin{lemmacorrectness}
	\correctnesslemma
\end{lemmacorrectness}

\begin{proof}
In order to ensure correctness we must ensure that $b< q/2$ and that $|f|\leq b$. To show this we show that in each recursion step the honest prover's witness polynomial has coefficients bounded by $b$ and is $\mu$-linear. 
We argue inductively that for each recursive call of $\pro{EvalB}$ the following constraints on the inputs are satisfied: $f(X_1\dots,X_\mu)$ is $\mu$-linear. $\gr{C}$ encodes the polynomial, \emph{i.e.}, $\gr{C}=\gr{g}^{f(\vec{q})}$ and $f(X)\in \ZZ(b)$. Also $f(z_1,\dots,z_\mu) = y\bmod p$.

Initially, during the execution of $\eval$, the prover maps the coefficients of a polynomial $\tilde{f}(X_1,\dots,X_\mu)\in \ZZ_p$ to a $\mu$-linear integer polynomial $f(X_1,\dots,X_\mu)$ with coefficients in $\ZZ(p-1)$  such that $\gr{C}=\gr{g}^{f(\vec{q})}$. Additionally $f(z_1,\dots,z_\mu)\bmod p=\tilde{f}(z_1, \dots,z_\mu)=y$.

 
If $f$ is $\mu$-linear then in round $i$ of the protocol the $\prover$ can compute $i-1$ linear polynomials $f_L$ and $f_R$ such that $f_L(X_1,\dots,X_{i-1})+X_i f_R(X_1,\dots,X_{i-1})=f(X_1,\dots,X_i)$. Consequently $f(z_1,\dots,z_{i}) \bmod p=f_L(z_1,\dots,z_{i-1})+ z_i f_R(z_1,\dots,z_{i-1})\bmod p=y_L+z_i  y_R\bmod p =y$. The \textsf{PoE} protocol has perfect correctness so {$\gr{g}^{f_L(q)+q^{\frac{d+1}{2}} f_R(X)}=\gr{C}$}.
 %\gr{C}_L\gr{C}_R^{(q^{\frac{d+1}{2}})}
 Finally $f'= f_L +\alpha\cdot  f_R \in \ZZ(2^{\lambda} \cdot b)$ is an $i-1$-linear polynomial with coefficients bounded in absolute value by $(2^\lambda-1) \cdot b+b=2^{\lambda} b$, as $\alpha\in [0,2^\lambda)$. This is precisely the value of $b'$ the input to the next call of $\pro{EvalB}$. The value $y'$ is also correct:
$f'(z_1,\dots,z_{i-1})\bmod p=f_L(z_1,\dots,z_{i-1}) +\alpha  \cdot f_R(z_1,\dots,z_{i-1}) \bmod p= y_L +\alpha  \cdot y_R\bmod p=y'$
 
 In the final round, the prover sends $f$, and the verifier checks that $|f|<b$ which is true by construction.
\end{proof} 

\subsection{Soundness}
\label{sec:darksoundness}
\paragraph{Security of $\textsf{PoE}$ substitutions}
We first begin by showing that we can safely replace all of the $\textsf{PoE}$ evaluations with direct verification checks. Concretely, under the Adaptive Root Assumption, the $\eval$ protocol is as secure as the protocol $\eval'$ in which all $\textsf{PoE}$s are replaced by direct checks. We show that the witness-extended emulation for $\eval'$ implies the same property for $\eval$. This is useful because we will later show how to can build an extractor for $\eval'$, thereby showing that the same witness-extended emulation property extends to $\eval$.

\benedikt{update for multi-linear}
\begin{lemma} \label{lemma:poe_security}
Let $\eval'$ be the protocol that is identical to $\eval$ but in line \ref{line:PoE} of $\pro{EvalB}$ $\verifier$ directly checks $\gr{C}_L+ q^{(2^{\mu-1})} \cdot \gr{C}_R=\gr{C}$ instead of using a $\textsf{PoE}$. If the Adaptive Root Assumption holds for $\ggen$, and $\eval'$ has witness-extended emulation for $O(\log(\lambda))$-linear polynomials, then so does $\eval$.
\end{lemma}

\begin{proof}
We show that if an extractor $E'$, as defined in Definition~\ref{def:wee}, exists for the protocol $\eval'$ then we can construct an extractor $E$ for the protocol $\eval$. Specifically, $E$ simulates $E'$ and presents it with a $\pro{Record}'(\cdots)$ oracle, while extracting the witness from its own $\pro{Record}(\cdots)$ oracle.

Whenever $E'$ queries the $\pro{Record}'$ oracle, $E$ queries its $\pro{Record}$ oracle and relays the response after dropping those portions of the transcript that correspond to the $\mathsf{PoE}$ proofs. Whenever $E'$ rewinds its prover, so does $E$ rewind its prover. When $E'$ terminates by outputting a transcript-and-witness pair $(\mathsf{tr}', f(X))$, $E$ adds $\mathsf{PoE}$s into this transcript to obtain $\mathsf{tr}$ and outputs $(\mathsf{tr}, f(X))$.

For each PPT adversary $(\adv,P^*)$, $E$ will receive a polynomial number of transcripts from its $\pro{Record}$ oracle. Any transcript $\tr$ of $\eval$ such that $\adv(\tr)=1$ and $\tr$ is accepting contains exactly $\mu$ $\textsf{PoE}s$ transcripts. 
So in total $E$ sees only a polynomial number of $\textsf{PoE}$ transcripts generated by a probabilistic polynomial-time prover and verifier. By Lemma~\ref{lem:poe} under the Adaptive Root Assumption, the probability that a polynomial time adversary can break the soundness of $\textsf{PoE}$, \emph{i.e.}, convince a verifier on an instance $(\gr{C}_R,\gr{C}-\gr{C}_{L},q^{(2^{\mu-1})})\not\in\mathcal{R}_{\textsf{PoE}}$, is negligible. 
Consequently, the probability that the adversary can break $\textsf{PoE}$ on \emph{any} of the polynomial number of executions of $\mathsf{PoE}$ is still negligible.

This means that with overwhelming probability all transcripts are equivalent to having the verifier directly check $(\gr{C}_R,\gr{C}-\gr{C}_{L},q^{(2^{\mu-1})})\in\mathcal{R}_{\textsf{PoE}}$. By assumption, the witness-candidate $f(X)$ that $E'$ outputs is a valid witness if the transcript $\mathsf{tr}'$ that $E'$ also outputs is accepting. The addition of honest $\mathsf{PoE}$ transcripts to $\mathsf{tr}'$ preserves the transcript's validity. So $\mathsf{tr}$ is an accepting transcript for $\pro{Eval}$ if and only if $\mathsf{tr}'$ is an accepting transcript for $\pro{Eval}'$. Therefore, $E'$ outputs a valid witness $f(X)$ whenever $E$ outputs a valid witness. This suffices to show that $\pro{Eval}$ has witness-extended emulation if $\pro{Eval}'$ has, and if the Adaptive Root Assumption holds for $\ggen$.
\end{proof}



%\def\thetheorem{\ref{thm:darkisdarkss}}
\newtheorem*{darkisdarkss}{Theorem \ref{thm:darkisdarkss}}
\begin{darkisdarkss}
\maintheorem
\end{darkisdarkss}

\begin{remark} $\mathsf{CSZ}_{\mu, \lambda}$ is derived from the Multilinear Composite Schwartz Zippel Lemma (\cref{lem:CSZ}). $\mathsf{EBL}_{\mu, \lambda}$ is derived from the Evaluation Bound Lemma (\cref{lem:evalbound}) and $\mathsf{CB}$ refers to the final round check bound in the DARK protocol. We can also substitute any value for $\mathsf{CSZ}_{\mu,\lambda}$ using the table of concrete bounds in Lemma~\ref{lem:cCSZ} for fixed $120$-bit security in place of the analytical bound from Lemma~\ref{lem:CSZ}).% which gives the same result for $\log q \geq 1 + 4(121 + \max(\EBL+ \CorrectnessBound , \mathsf{CSZ}_{\mu,\lambda}))$ and $\epsilon(\lambda) = \max(\frac{3\mu}{2^\lambda}, 2^{-120})$. \ben{This should be $\lambda$-bit security not 120-bit?}  	
\end{remark}



\begin{proof} 

For any $\beta_\textsf{n}, \beta_\textsf{d} \in \mathbb{R}$, let $\mathcal{M}(\beta_\textsf{n}, \beta_\textsf{d}) = \{f/N \in \QQ[X]: \gcd(f, N) = 1, ||f||_\infty \leq \beta_\textsf{n}, |N| \leq \beta_\textsf{d}\}$. In the relation $R(\mathsf{x}, \mathsf{w})$ for the DARK evaluation protocol, the input $\mathsf{x} = (C, \vec{z}=(z_1,\dots,z_\mu), y)$ consists of a DARK commitment $C$, an evaluation point $\vec{z}\in \ZZ^{\mu}$ and a claimed evaluation $y \in \ZZ$, while the witness $\mathsf{w}$ is an opening of $C$ to a rational $\mu$-linear polynomial $h$ such that $h(\vec{z}) = y \bmod p$. For any parameters $\beta_\textsf{n}, \beta_\textsf{d}$ such that $\beta_\textsf{n} \cdot \beta_\textsf{d} \leq \frac{q}{2}$ this is binding to rational polynomials in $\mathcal{M}(\beta_\textsf{n}, \beta_\textsf{d})$. Setup parameters include $p$ and $q$. 

For reasons that will become clear we will set: 
$$\log q = 4(\lambda + 1 + \CSZ[\mu]) + \EBL[\mu] + \CorrectnessBound + 1$$
$$\log_2 \beta_\textsf{n} = \frac{1}{2} (\mathsf{EBL}_{\mu, \lambda} + \mathsf{CB}_{p, \mu, \lambda} + \log_2 q - 1) \hspace{10mm} \log_2 \beta_\textsf{d} = \frac{1}{2} (\log_2 q - 1 - \mathsf{EBL}_{\mu, \lambda} -  \mathsf{CB}_{p, \mu, \lambda}) $$

so that $\log_2 (\beta_\textsf{n} \cdot \beta_{\textsf{d}}) = \log_2 q - 1$ as desired. 
\medskip 

We begin by defining $\textsf{com} = (\setup, \textsf{Commit}, \open)$ and predicates $\phi_a$ and $\phi_b$ for DARK special-soundness (Definition~\ref{def:darkspecialsoundness}). %We use the simplified notation $\phi_a, \phi_b: [\mu] \times \mathcal{M} \rightarrow \{0,1\}$ because in this case the predicates will only be functions of the messages and not the opening hints. 
 
\begin{itemize} 
\item The commitment setup $\textsf{com}.\setup(\lambda, \beta_\textsf{n}, \beta_\textsf{d})$ runs the setup procedure for the DARK commitment scheme, which samples a group $\mathbb{G} \gets \textsf{GGen}(\lambda)$, a generator $\gr{G} \gets \mathbb{G}$, sets $q = 2 \beta_\textsf{n} \beta_\textsf{d}$, and returns $\crs = (\mathbb{G}, \gr{G}, q)$. 
\item The commitments of $\textsf{com}$ are pairs $\mathcal{C} = ((C_L, y_L), (C_R, y_R)$ where $C_L, C_R$ are DARK commitments and $y_L, y_R \in \QQ$. Recall that $(f, N) \in \mathbb{Z}[X_1,\dots,X_\mu] \times \ZZ$ is an opening of a DARK commitment $C$ to the $\mu$-linear rational polynomial $h = f/N$ provided that  $f(q,\dots,q^{\mu-1}) \cdot \gr{G} = N \cdot C$, where $q$ is a parameter of the DARK commitment scheme. This is binding to rational polynomials in the set $\mathcal{M}(\beta_\textsf{n}, \beta_\textsf{d})$.

We define a valid opening of $\mathcal{C} = ((C_L, y_L), (C_R, y_R))$ to a rational $\mu$-linear polynomial $h \in \mathbb{Q}[X_1,\dots,X_\mu]$ as a pair $(f, N) \in \ZZ[X_1,\dots,X_\mu] \times \ZZ$ where $f = f_L + X_\mu f_R$ for $f_L, f_R \in \ZZ[X_1,\dots,X_{\mu-1}]$ such that $(f_L, N)$ and $(f_R, N)$ are valid openings of the DARK commitments $C_L$ and $C_R$ respectively, provided that $N \cdot h = f$, $f_L(\vec{z}) = N \cdot y_L \bmod p$, $f_R(\vec{z}) = N \cdot y_R \bmod p$. This also implies that $(f, N)$ is a valid opening of the homomorphically derived DARK commitment $C = C_L + q^{2^{\mu-1}} C_R$ to $h$ and $h(z_1,\dots,z_\mu) = y_L + z_\mu y_R \bmod p$, i.e. $N \cdot C = f(q,\dots,q^{2^{\mu-1}}) \cdot \gr{G}$ and $h \in \mathcal{M}(\beta_\textsf{n}, \beta_\textsf{d})$. %Such an opening may be derived from individual openings of $C_L$ to $h_L$ and $C_R$ to $h_R$ where $h_L(z) = y_L \bmod p$ and $h_R(z) = y_R \bmod p$. 
 %DARK openings of $C_L$ to $h_L$ and $C_R$ to $h_R$ such that $deg(h_L), deg(h_R) < \frac{d}{2}$ and $h = h_L +  X^{\frac{d}{2}} h_R$.  These commitments and openings also can be used to derive an opening of the DARK commitment 

Additionally, a rational number is also considered a valid (trivial) commitment to itself. In the DARK protocol the prover's messages are commitments of the first kind for all but its last message, which is a single integer. 

\item We define the numerator bounds $B_0\geq \cdots \geq B_\mu \in \mathbb{N}$ and denominator bounds $D_0 \geq \cdots \geq D_\mu$ such that $\log B_\mu = \CorrectnessBound$ is the verification bound on the prover's final integer message in the DARK protocol, $D_\mu = 1$ (i.e., prover's final message is an integer), $\log D_i = \CSZ[\mu - i]$ and $\log B_i = \CSZ[\mu - i] + \EBL[\mu - i] + \CorrectnessBound$. 

For $i \in [\mu-1]$ and any $h \in \QQ[X_1,\dots,X_{\mu-i}]$, we define $\phi_a(i, h) = 1 $ if and only if $h$ is $\mu-i$ linear and $h \in \mathcal{M}(B_i, D_i)$. In particular, $\phi_a(\mu, h) = 1$ iff $h \in \ZZ$ and $|h| \leq B_\mu$. 

\item For $i \in [\mu-1]$ and an opening $h \in \QQ[X_1,\dots X_{\mu-i}]$ define $\phi_b(i, h) = 1$ if and only if $h$ is $\mu-i$ linear and $h \in \mathcal{M}(2^{\lambda + 1} B_i D_i, 2^{\lambda + 1} D_i^2)$. 

\end{itemize}
By setting $q$ sufficiently large so that $\log q \geq 4(\lambda + 1 + \CSZ[\mu]) + \EBL[\mu] + \CorrectnessBound + 1$, for any $i \in [\mu]$, $\phi_b(i, h) = 1$ implies that $2^{\lambda + 1} \cdot h \in \mathcal{M}(\beta_\textsf{n}, \beta_\textsf{d})$. To see this, the log of the numerator bound on $2^{\lambda + 1} h$ is: 

$$2(\lambda + 1) + \log (B_0 D_0) = 2(\lambda + \CSZ[\mu] + 1) + \EBL[\mu] + \CorrectnessBound \leq \frac{1}{2}(\log q - 1 + \EBL[\mu] + \CorrectnessBound) = \log \beta_\textsf{n}$$ 
And the log of the denominator bound on $2^{\lambda + 1} h$ is: 
$$2(\lambda + 1 +  \CSZ[\mu]) \leq \frac{1}{2}(\log q - 1 - \EBL[\mu] - \CorrectnessBound) = \log \beta_\textsf{d}$$

Next, we define the algorithms $\textsf{Extract}$ and $\textsf{Extend}$. 

\begin{itemize} 
\item $\textsf{Extract}(i, \nu, C_\nu, \textsf{openSubtree})$ for $i < \mu$ operates as follows. Let $\mathcal{C}_\nu = (C_L, C_R)$. The node $\nu$ has two children. Let $\alpha_1$ denote the label on the edge to the first child and $\alpha_2$ the label on the edge to the second child. For $j \in \{1,2\}$, let $\mathcal{C}_j = ((C_{j,L}, y_{j, L}), (C_{j,R}, y_{j,R}))$ denote the commitment label of the $i$th child with openings $(f_j, N_j)$ to $h_j = f_j/N_j$ where for $i<\mu-1$ $f_j = f_{j, L} + X_{\mu - i - 1} f_{j, R}$, and $h_j(z) = y_{j,L} + z_{{\mu - i -1}}\cdot  y_{j,R} \bmod p$. Set $N = (\alpha_2 - \alpha_1) N_1 N_2$, $f_L = \alpha_2 N_2 f_1 - \alpha_1 N_1 f_2$, and $f_R = N_1 f_2 - N_2 f_1$. Set $f = f_L + X_{{\mu - i }}\cdot f_R$. Return $(f, N)$ as the opening for $C_\nu$ to $h = f/N$. 


\item \textsf{Extract}(0, (C, z, y), \textsf{openTree}) simply returns the opening $(f, N)$ for the root level commitment $((C_L, y_L), (C_R, y_R))$ to $h = f/N$, which satisfies $N \cdot C = f(q) \cdot \gr{G}$ and $h(z) = y$, since in a valid transcript tree $C = C_L + q^{2^{\mu -1}} C_R$ and $y_L + z_{\mu} \cdot y_R = y$.  Furthermore, if $\phi_a(0, h) = 1$ then $h \in \mathcal{M}(B_0, D_0) \subset \mathcal{M}(\beta_\textsf{n}, \beta_\textsf{d})$, and hence $\mathsf{w} = (f, N)$ is a witness for $\mathsf{x} = (C, z, y)$ such that $R(\mathsf{x}, \mathsf{w}) = 1$. 

%\textbf{Notes:} Let $f_L/N_L = h_L$ and $f_R/N_R = h_R$ denote the reduced forms. Since $C_L^{N_L} = g^{f_L(q)}$ and $C_R^{N_R} = g^{f_R(q)}$ and $C = C_L \cdot C_R^{q^{d/2}}$ it follows that $C^N = g^{f(q)}$. Furthermore, $N \leq lcm(N_L, N_R) \leq B_0^2$ and $||f|| \leq B_0^2 \cdot max(||f_L||, ||f_R||)$. 


\item $\textsf{Extend}(i, h, \alpha_{i+1},...,\alpha_\mu)$ on $h \in \mathbb{Q}[X_1,\dots,X_{\mu-i}]$ returns $\bot$ if $h$ is not $\mu-i$ linear, and otherwise sets $h_i := h$ and runs the following iterative algorithm: for $j = i$ to $\mu-1$ set $h_{j+1} := h_{j, L} + \alpha_{j+1} \cdot h_{j,R}$ where, treating each $h_j$ as a ${\mu - j}$ linear polynomial (padding with zero coefficients), $h_{j,L}$ and $h_{j, R}$ are each ${\mu -j - 1}$ linear consisting of the left/right coefficients (i.e. the constant and linear part of $X_{\mu-j}$) of $h_j$, i.e. $h_j = h_{j,L} + X_{{\mu - j}}\cdot  h_{j,R}$; return $h_i,...,h_\mu$. \benedikt{double check the indices. I did but it's easy to be off by one}

\textbf{Notes:} 
The runtime is $O(\lambda \cdot 2^{\mu - i})$. 

If $h_{i}=h_{i,L} + X_{\mu-i}\cdot  h_{i,R}  \in \mathbb{Z}[X_1,\dots,X_{\mu-i}]$ is the prover's committed polynomial in the $i$th round of the (honest) interactive DARK protocol and $\alpha_{i+1},...,\alpha_\mu$ are the last $\mu - i$ round challenges then $h_\mu$ is the last prover's message sent to the verifier in the interactive DARK protocol. Then $h_\mu=h_i(\alpha_{\mu},\dots,\alpha_{i+1})$

% Let $\mu' = \mu - i$. For $b = (b_1,...,b_{\mu'}) \in \{0,1\}^{\mu'}$ let $\sigma(b) = \sum_{j =1}^{\mu'} b_j \cdot 2^{\mu' - j + 1}$, i.e. $b$ is the binary big-endian representation of $\sigma(b)$. Then $h_\mu = g(r_{i+1},...,\alpha_\mu)$ where $g(X_1,...,X_{\mu'}) = \sum_{b \in \{0,1\}^{\mu'}} h_{\sigma(b)} \prod_{j=1}^{\mu'}X_j^{b_i}$ where $h_j$ is the $j$th coefficient of $h \in \mathbb{Q}[X]$. 
 
 \item $\textsf{Break}(i, h, \alpha_1,...,\alpha_\mu, C_0,...,C_\mu, (f_i, N_i),...,(f_\mu, N_\mu))$\footnote{For simplicity, we omit the messages $h_i = f_i/N_i$ from the inputs because it can be computed from the opening $(f_i, N_i)$.}  first runs $\textsf{Extend}(i, h, \alpha_i,..,\alpha_{\mu})$, which returns rational polynomials $h'_{i+1},...,h'_{\mu}$. If $\forall_{j \geq i}$ $h'_j = f_j/N_j$ then it outputs $\bot$. Otherwise, let $j \in [i, \mu)$ be the \textit{first} index where $h'_{j+1}\neq f_{j+1}/N_{j+1}$ and output $(N_j, f_{j, L} + \alpha_{j+1} \cdot  f_{j, R})$, where $f_{j, L}$ and $f_{j, R}$ are the left/right halves of $f_j$, as the attempted opening for $C_{j+1}$.
\end{itemize}

\begin{subclaim} 
For $i \in [\mu-1]$, if all openings of commitments on children of $\nu$ in $\textsf{openSubtree}$ satisfy $\phi_a(i+1, *)=1$ then the tuple $(f_L, f_R, N)$ returned by $\textsf{Extract}(i, \nu, \mathcal{C}_\nu, \textsf{openSubtree})$ is a valid opening for $\mathcal{C}_\nu$ to a rational polynomial $h$ that satisfies $\phi_b(i, h) = 1$ 
\end{subclaim} 

\begin{proof}
We will show why this is a correct opening for $\mathcal{C}_\nu$ and bound its norm. Based on the properties of a valid transcript tree, $\forall_{j \in \{1,2\}} C_L + \alpha_j C_R =  C_{j,L} + q^{2^{\mu - i - 2}} C_{j,R}$ and $y_L + \alpha_j y_R = y_{j,L} + z_{{\mu - i 12}} y_{j, R}$. Furthermore, $\forall_{j \in \{1,2\}} N_j \cdot (C_L + \alpha_j C_R ) = f_j(q)$ and $h_j(z) = N_j^{-1} f_j(z) = y_L + \alpha_j y_R \bmod p$ by the assumption that $(f_j, N_j)$ are valid openings to the two children commitments $\mathcal{C}_j$.  Let $L_q(\cdot): \ZZ[X]^2 \rightarrow \ZZ^2$ denote the linear operator corresponding to component-wise evaluation of each polynomial at $\vec{q}$. Using linear algebra, the following holds true if $\alpha_1 \neq \alpha_2$:
\begin{equation*}
\begin{array}{c}
\begin{bmatrix}
N_1 & 0 \\
0 & N_2 \\
\end{bmatrix} 
\begin{bmatrix}
1 & \alpha_1 \\
1 & \alpha_2 \\
\end{bmatrix} 
\begin{bmatrix}
C_L \\
C_R \\
\end{bmatrix} 
= 
L_q \left(
\begin{bmatrix}
f_1 \\
f_2\\
\end{bmatrix} 
\right)
 \cdot \gr{G} \\
\Downarrow\\
(\alpha_2 - \alpha_1) N_1 N_2 
\begin{bmatrix}
C_L \\
C_R \\
\end{bmatrix}
= 
L_q\left(
\begin{bmatrix}
\alpha_2 N_2 & -\alpha_2 N_1 \\
-N_2 & N_1 \\
\end{bmatrix}
\begin{bmatrix}
f_1 \\
f_2 \\
\end{bmatrix}
\right)
\cdot  \gr{G}
\end{array} 
\end{equation*}
and
\begin{equation*}
\begin{array}{c}
\begin{bmatrix}
N_1 & 0 \\
0 & N_2 \\
\end{bmatrix} 
\begin{bmatrix}
1 & \alpha_1 \\
1 & \alpha_2 \\
\end{bmatrix} 
\begin{bmatrix}
y_L \\
y_R \\
\end{bmatrix} 
= 
L_z \left(
\begin{bmatrix}
f_1 \\
f_2\\
\end{bmatrix}
\right) \bmod p\\
\Downarrow\\
(\alpha_2 - \alpha_1) N_1 N_2 
\begin{bmatrix}
y_L \\
y_R \\
\end{bmatrix}
= 
L_z \left(
\begin{bmatrix}
\alpha_2 N_2 & -\alpha_2 N_1 \\
-N_2 & N_1 \\
\end{bmatrix}
\begin{bmatrix}
f_1 \\
f_2 \\
\end{bmatrix}
\right)
\bmod p
\end{array}
\end{equation*} 
This shows that $N \cdot C_L = f_L(q) \cdot \gr{G}$, $N \cdot C_R = f_R(\vec{q}) \cdot \gr{G}$, $N \cdot y_L = f_L(\vec{z}) \bmod p$, and $N \cdot y_R = f_R(\vec{z}) \bmod p$. Furthermore, if $f_1$ and $f_2$ are $\mu-i$ linear, then so are $f_L$ and $f_R$. 
%$$N \cdot (C_L + q^{2^{\mu - i - 1}} C_R) = (f_L(q) + q^{2^{\mu - i -1}} f_R(q)) \cdot \gr{G} = f(q) \cdot \gr{G}$$ 

%$$ \frac{f_L}{N_L} = \frac{N_2 \alpha_2 f_1 - N_1 \alpha_2 f_2}{(\alpha_2 - \alpha_1)N_1 N_2 } \ \ \text{and} \ \ \frac{f_R}{N_R} = \frac{N_1 f_2 - N_2 f_1}{(\alpha_2 - \alpha_1) N_1 N_2}$$

If $\forall _j ||f_j||_\infty \leq B_i$ and $\forall_j |N_j| \leq B_i$,  then $|N|  \leq 2^{\lambda + 1} D_i^2$ and $||f||_\infty \leq 2^{\lambda + 1} B_i D_i$. Thus, if the openings of the children at level $i+1$ satisfy $\phi_a(i+1, f_j/N_j) = 1$ for $j \in \{1, 2\}$, then $\phi_b(i, f/N) = 1$. %In other words, if the openings $(f_j, N_j)$ for $h_j = f_j/N_j$ of the children at level $i+1$ satisfy $\phi_a(i+1, h_j, f_j, N_j) = 1$ then $\phi_b(i, h, f, N) = 1$. 
\end{proof} 



\begin{subclaim} [\emph{Key *New* Subclaim}]
For any $i \in [\mu]$ and $h \in \mathbb{Q}[X_1,\dots,X_{\mu-i}]$, if $\phi_a(i, h) = 0$ then the probability over uniform i.i.d. $\alpha_{i+1},...,\alpha_\mu$ that $h_\mu$ returned by $\textsf{Extend}(i,h, \alpha_{i+1},...,\alpha_\mu)$ satisfies $\phi_a(\mu, h_\mu) = 1$ is at most $\frac{3(\mu - i)}{2^\lambda}$. 
\end{subclaim} 

Let $f/N = h$ for $\gcd(f, N) = 1$ denote the reduced form of $h \in \mathbb{Q}[X_1,\dots,X_{\mu-i}]$. If $\phi_a(i,h) = 0$ then either $N > D_i$ or $||f||_\infty > B_i$ while $\phi_a(\mu, h_\mu) = 1$ implies $h_\mu \in \mathbb{Z}$ and $|h_\mu| \leq B_\mu$.

 Let $\mu' = \mu - i$. Observe that $h_\mu = \frac{1}{N} \cdot f(\alpha_{\mu},...,\alpha_{i+1})$. \\
 
 \noindent \textbf{Case 1 $N > D_i$}: 
 
 If $|N| > D_i$ then since $\log D_i = \mathsf{CSZ}_{\mu - i}$, the probability that $h_\mu \in \mathbb{Z}$ is:
 $$\Prob_{(\alpha_{i+1},...,\alpha_\mu) \gets [0,2^\lambda)^{\mu -i}} [f(\alpha_{\mu},...,\alpha_{i+1})\equiv 0 \bmod N]  \leq \frac{\mu - i +1}{2^\lambda}$$
by the Multilinear Composite Schwartz-Zippel Lemma (Lemma~\ref{lem:CSZ}).\\

 
\noindent \textbf{Case 2 $N \leq D_i \ \wedge \ ||f||_\infty > B_i$}: 
 
In this case if $|h_\mu| \leq B_\mu$ then $|f(\alpha_{\mu},...,\alpha_{i+1})| \leq N \cdot B_\mu \leq \CSZ[\mu - i] \cdot B_\mu$. 
 Furthermore, the fact that $||f||_\infty > B_i$ and $\log B_i = \CSZ[\mu - i] + \EBL[\mu - i] + \log B_\mu$ imply: 
 $$\log (\CSZ[\mu -i] \cdot B_\mu) \leq \log B_i - \EBL[\mu - i ] < \log ||f||_\infty - \EBL[\mu - i]$$
 
Hence by the Evaluation Bound Lemma (Lemma~\ref{lem:evalbound}): 
$$\Prob[h_\mu \leq B_\mu] \leq \Prob[|f(\alpha_{\mu},...,\alpha_{i+1})| \leq D_i \cdot B_\mu] \leq \Prob[|f(\alpha_{\mu},...,\alpha_{i+1})| \leq \frac{1}{2^{\EBL[\mu - i]}} \cdot ||f||_\infty] \leq  \frac{3(\mu- i)}{2^{\lambda}}$$

 
Together these imply that if $f$ is $\mu-i$ linear but $\phi_a(i, f/N) = 0$ then, since either $|N| > B_i$ or $||f||_\infty > B_i$, the probability over the random challenges that the final element $h_\mu$ of the list returned by $\textsf{Extend}$ satisfies $\phi_a(\mu, h_\mu) = 1$ is negligible. 

\end{proof} 

\begin{subclaim} 
 For any $i \in [\mu-1]$, given a valid (accepting) transcript with commitments $(\mathcal{C}_0,...,\mathcal{C}_\mu)$, round challenges $(\alpha_1,...,\alpha_\mu)$, and openings $(o_i,...,o_\mu)$ of the last $\mu-i + 1$ commitments to rational polynomials $(h_i,,...,h_\mu)$, where $\phi_b(i, h_i) = 1$ and $\phi_a(j, h_j) = 1$ for all $j \in [i+1,\mu]$, then either $\textsf{Extend}(i, h_i, \alpha_{i+1},...,\alpha_\mu)$ returns $h_{i+1},...,h_{\mu}$ or $\textsf{Break}(i, h_i, (h_i, o_i),...,(h_\mu, o_\mu))$ returns for some $j \geq i$ a valid opening of $\mathcal{C}_j$ to $h'_j \neq h_j$.  %in time $t_E$ with overwhelming probability $1 - \mathsf{RSA}(\GG, t_\mathcal{A} + t_E)$ over the internal randomness of $\mathcal{A}$, where $\mathsf{RSA}(\GG, t)$ denotes the maximum success probability of any $t$-step algorithm in breaking the Strong RSA Assumption over $\GG$. 
\end{subclaim} 
\begin{proof} 
Let $(h'_{i+1},...,h'_\mu)$ denote the output of $\textsf{Extend}(i, h_i, \alpha_{i+1},...,\alpha_\mu)$ and suppose it is not equal to $(h_{i+1},..., h_\mu)$. Let $j \in [i, \mu)$ denote the \emph{first} index for which $h_{j+1} \neq h'_{j+1}$. This means that $h_j = h'_j$ and thus $h'_{j+1} = h_{j, L} + \alpha_{j+1} \cdot h_{j, R}$ where $h_{j, L}$ and $h_{j, R}$ are the left/right halves of $h_{j}$. Additionally, $\phi_b(j, h_{j}) = 1$ implies $h'_{j+1} \in \mathcal{M}(2^{2\lambda + 2} B_{j}D_j, 2^{\lambda + 1} B_{j}^2) \subseteq \mathcal{M}(\beta_\textsf{n}, \beta_\textsf{d})$. 

(Note that for $j \geq i+1$, the condition $\phi_a(j, h_j) = 1$ also implies $\phi_b(j, h_j) = 1$).

Let $\mathcal{C}_{j+1} = ((C_{j+1, L}, y_{j+1,L}), (C_{j+1,R}, y_{j+1,R}))$ and $\mathcal{C}_{j} = ((C_{j,L}, y_{j,L}), (C_{j,R},y_{j,R}))$. 
Let $o_j = (f_j, N_{j})$ denote the opening of $\mathcal{C}_{j}$ to $h_j =\frac{f_j}{N_{j}}$ where $f_{j} = f_{j, L} + X_{{\mu - j }} f_{j, R}$\benedikt{Check index of $X$}. Validity of the opening implies $N_{j} \cdot C_{j,L} = f_{j,L}(q) \cdot \gr{G}$ and $N_{j} \cdot C_{j,R} = f_{j,R}(q) \cdot \gr{G}$. Furthermore, in a valid transcript: 
 $$C_{j+1}  = C_{j, L} + \alpha_{j+1} \cdot C_{j,R} =  C_{j+1,L} + q^{2^{\mu - j}} C_{j+1,R}$$
  Thus, $(N_{j}, f_{j,L} + \alpha_{j+1} \cdot f_{j, R})$ is a valid opening of $C_{j+1}$ to $h'_{j+1}$ as $N_{j} \cdot C_{j+1} = (f_{j, L}(q) + \alpha_{j+1} \cdot f_{j, R}(q)) \cdot \gr{G}$. 
  
\paragraph{Witness-extended emulation}
By \cref{cor:dsstowee} and if the DARK commitment is binding then this shows that $\eval'$ has witness extended emulation for the relation $\reval(\params)$ for polynomials in $\FF_p$. The binding property of DARK depends on the random order assumption which is implied by the adaptive root assumption (\Cref{lem:darkcommit,lem:roa-to-ar}). Further by \Cref{lemma:poe_security} this implies that $\eval$ has witness-extended emulation for the same relation under the adaptive root assumption.

\end{proof} 









\section{Fiat-Shamir Transform of Almost-Special-Sound Protocols} 
Recently, \cite{EPRINT:Wikstrom21,EPRINT:AttFehKlo21} showed that for $\mu$-round special sound protocols the non-interactive Fiat-Shamir transform of these protocols only suffers a security loss that is linear in the number of queries the adversary makes to the random oracle. These proofs do not directly apply to almost-special-sound protocols. In particular, in a non-interactive protocol, we cannot guarantee that the challenges on $\textsf{lpath}(\nu)$ are mutually independent. An adversary might grind each challenge and pick one depending on the previous challenges. Concretely, for DARK the composite Schwartz-Zippel lemma analyzes the probability that $f(x_1,\dots,x_\mu)\equiv 0 \bmod N$ for \emph{independently} sampled $x_1,\dots,x_\mu$. If the adversary, can grind challenges, i.e. try different challenges per prover message, then it can for each challenge $x_i$ ensure that $f(x_1,\dots,x_i,X_{i+1},\dots,X_\mu)\equiv 0 \bmod N_i$ where $N_i$ is a factor of $N$ of size roughly $N^{\frac{1}{\mu}}$. The proof of \cref{thm:darkisdarkss} relies on the fact that $\Prob_{(\alpha_{i+1},...,\alpha_\mu) \gets [0,2^\lambda)^{\mu -i}} [g(\alpha_{i+1},...,\alpha_\mu)\equiv 0 \bmod N]=\delta$ is negligible for sufficiently large $N$. Analyzing a grinding adversary of the non-interactive protocol that makes at most $T$ queries to the random oracle corresponds to analyzing the probability that for any set of $T$ values $\Prob_{S=\{\alpha_{i,j}\}_{i\in [\mu], j \in [T]}) \gets [0,2^\lambda)^{\mu \cdot T}}  \exists (j_1,\dots,j_\mu) \text{ s.t. } [g(\alpha_{1,j_1},...,\alpha_{\mu,j_\mu})\equiv 0 \bmod N]$ which using a union bound is less than $T^\mu \cdot \delta$.

However, what if it is impossible for the adversary to actually grind the prover message. We know that in almost-special-sound protocols the prover message is a commitment. If that commitment is unique, i.e. for a given opening there exists only one possible commitment, then a grinding adversary couldn't choose a different commitment. We capture this notion formally and show that even if the commitment is only \emph{computationally unique} the Fiat-Shamir transform of these almost-special-sound protocols is secure. The DARK protocol has precisely this property.

\begin{definition}[Random Oracle]
	In our version of the random oracle model, all random oracle algorithms have black-box access to a shared random function $\mathcal{H}: \mathcal{M}^{\leq u} \rightarrow \mathcal{X}$ where $\mathcal{M}^{\leq u}$ consists of all vectors $(m_1,...,m_i) \in \mathcal{M}^i$ for each $i \leq u$. $\mathcal{H}$ assigns to each of the $\frac{|\mathcal{M}|^{u + 1} - 1}{|\mathcal{M}| - 1}$ unique elements of $\mathcal{M}^{\leq u}$ an output independently and uniformly distributed in $\mathcal{X}$. Random oracles may be assigned indices from a set $\mathcal{I}$, where for any distinct $i,j \in \mathcal{I}$ the oracles $\mathcal{H}_i$ and $\mathcal{H}_j$ are independently distributed random functions. For any $k < u$ and fixed $\mathbf{m} = (m_1,...,m_k)$ we will use the notation $\mathcal{H}_\mathbf{m}: \mathcal{M}^{\leq u - k} \rightarrow \mathcal{X}$ where $\mathcal{H}_\mathbf{m}(m'_1,...,m'_i) = \mathcal{H}(\mathbf{m}, m'_1,...,m'_i)$ for any $i \leq u - k$. This is equivalent to a random oracle family indexed by $\mathcal{M}^k$. 
\end{definition}
A \emph{$Q$-query random oracle algorithm} is an algorithm that makes at most $Q$ queries to the random oracle. 


\begin{definition} [Non-interactive Proof of Knowledge in RO]\label{def:ROproof}
  
An non-interactive protocol $\Pi = (\prover, \verifier)$ between a prover $\prover$ and verifier $\verifier$ in the random oracle model (i.e., with shared oracle access to the random function $\mathcal{H}$) is a proof of knowledge for a relation $\mathcal{R}$ with knowledge error $\delta:\mathbb{N}^2 \rightarrow [0,1]$ if the following properties hold:
\begin{itemize}
\item \underline{Perfect Completeness:} for all $(x,w) \in \mathcal{R}$
\begin{small}
\[
\mathbb{P} \left[\verifier^\mathcal{H}(x, \pi) = 1  : \pi \gets \prover^{\mathcal{H}}(x, w)
\right]  = 1 
 \]
 \end{small}
\item \underline{$\delta$-Knowledge Soundness:}
There exists a polynomial $\textsf{poly}(\cdot)$ and a probabilistic oracle machine $\mathcal{E}$ called the \emph{extractor} such that given oracle access to any $Q$-query random oracle algorithm $\mathcal{A}$ and any input $x \in \mathcal{L}_R$ the following holds\footnote{The algorithm $\mathcal{A}$ may explicitly hardcode a witness or may not have one, so no witness is given to $\mathcal{A}$ as input.}: if
\[\mathbb{P} \left[\verifier^\mathcal{H}(x, \pi) = 1  : \pi \gets \mathcal{A}^{\mathcal{H}}(x)
\right]  = \epsilon(x)\]
 then $\mathcal{E}^\mathcal{A}(x)$ outputs $w$ such that $(x, w) \in \mathcal{R}$ in an expected $\frac{\mathsf{poly}(|x|)}{\epsilon(x) - \delta(|x|, Q)}$ number of steps. In the course of running with black-box access to $\mathcal{A}$, $\mathcal{E}^\mathcal{A}(x)$ implements the random oracle for $\mathcal{A}$, i.e. it intercepts all queries that $\mathcal{A}$ makes to $\mathcal{H}$ and simulates the response. 
 \end{itemize} 
 $\Pi$ is called ``knowledge sound" or a ``proof of knowledge" for $\mathcal{R}$ if for all $Q$ polynomial in $|x|$ the knowledge error $\delta(|x|, Q)$ is a negligible function of $|x|$.  
\end{definition} 

\begin{definition}[Non-interactive argument of knowledge in SRS/RO]\label{def:ROargument}
	A non-interactive proof system $\Pi = (\setup, \prover^\mathcal{H}, \verifier^\mathcal{H})$ with setup procedure $\crs \gets \setup(\lambda)$ in the random oracle model, where $\prover^\mathcal{H}$ and $\verifier^\mathcal{H}$ are given shared access to both the random oracle $\mathcal{H}$ and the parameters $\crs$ (where $|\crs| \geq \lambda$), is an argument of knowledge for relation $\mathcal{R}$ with knowledge error $\textsf{err}: \mathbb{N}^2 \rightarrow [0,1]$ if there exists a polynomial time extractor $\mathcal{E}$ such that for any non-uniform polynomial time adversary $\mathcal{A}$ and deterministic $Q$-query polynomial time prover $P^*$ the following holds:\footnote{This definition says that there is overwhelming intersection between the event where the adversary generates an input $x$ and corresponding proof $\pi$ that convinces the verifier, and the event where the extractor succeeds in obtaining a witness from the input $x$ generated by the adversary. This not only ensures that extraction succeeds with close to the same probability of the adversary's success over randomly sampled parameters, but also excludes the pathological case that both the adversary and extractor succeed with noticeable probability on disjoint sets of inputs. This definition is also equivalent to fixing the transcript distinguisher in the definition of witness-extended emulation (Definition~\ref{def:wee}) to be the verifier decision algorithm. In WEE the transcript distinguisher could be arbitrary, which is a stronger property important for simulation analysis.}
	\begin{small}
	\[ 
	\mathbb{P} \left[
	\begin{array}{c} 
	(x,w) \in \mathcal{R} \ and \\\ 
    \verifier^\mathcal{H}(\crs, x, \pi) = 1 
	\end{array} : 
	\begin{array}{c}
	\crs \gets \setup(\lambda) \\
	(x, \st) \gets \mathcal{A}(\crs) \\ 
	\pi \gets P^*(\st) \\ 
	w \gets \mathcal{E}^{P^*(\st)}(\crs, x) 
	\end{array}
 \right] \geq \mathbb{P} \left[
	\begin{array}{c} 
	\verifier^\mathcal{H}(\crs, x, \pi) = 1 
	\end{array} : 
	\begin{array}{c}
	\crs \gets \setup(\lambda) \\
	(x, \st) \gets \mathcal{A}(\crs) \\ 
	\pi \gets P^*(\st) \\ 
	\end{array}
 \right] -  \textsf{err}(\lambda, Q)
	\]
	\end{small}
\end{definition}


%\paragraph{Witness-extended emulation in RO} Witness-extended emulation for non-interactive proofs in the RO model with a structured reference string (SRS), i.e. with setup, is defined in nearly the same way as Definition~\ref{def:wee}. The only change is that the prover and verifier are random oracle algorithms and the emulator programs the oracle for $\prover^*$ when interacting with its transcript oracle. The fact that knowledge soundness for a relation $\mathcal{R}$ implies witness-extended emulation for $\mathcal{R}$ (Lemma~\ref{lem:wee}) remains true in the RO model. 

%\ben{Find formal citation? I believe it is trivial extension of Lemma~\ref{lem:wee}} 

\begin{definition}[FS Transform]
For any $\mu$-round public-coin interactive proof $\Pi$ the FS transform $\Pi^{\mathcal{H}}_{FS}$ of $\Pi$ with respect to the random oracle $\mathcal{H}$ is a non-interactive proof in the random oracle model which on public input $\mathsf{x}$ simulates the interactive protocol $\Pi$ by replacing each $i$th round public-coin challenge, for $i \in [1, \mu]$, with $\mathcal{H}(\mathsf{x}, m_1,...,m_i)$, where $m_1,...,m_i$ denote the first $i$ prover messages. 
\end{definition}

\begin{lemma}[FS for special-sound multiround protocols~\cite{EPRINT:AttFehKlo21,EPRINT:Wikstrom21}] \label{lem:FSSoundness}
	For any $\mu$-round interactive proof $\Pi = (\prover, \verifier)$ for relation $\mathcal{R}$ and its FS transform $\Pi_{FS} = (\prover^\mathcal{H}, \verifier^\mathcal{H})$ with random oracle $\mathcal{H}$, there exists a random oracle algorithm $\textsf{Tree}$ which given black-box access to any $Q$-query deterministic prover algorithm $\prover^*$, input $x \in \mathcal{L}_R$, and $k \in \mathbb{N}$ makes at most $Q+\mu$ queries to $\mathcal{H}$ and returns a $k$-ary forking transcript tree for $\Pi$ in expected time $k^\mu + Q \cdot (k^\mu - 1)$ and succeeds with probability $\frac{\epsilon(x) - (Q+1) \cdot \kappa }{(1 - \kappa)}$ where $\kappa = 1 - (1 - \frac{k-1}{2^\lambda})^\mu$ and $\epsilon(x)$ is the probability (over $\mathcal{H}$) that $\prover^*$ outputs a non-interactive proof for $x$ that $\verifier^\mathcal{H}$ accepts. Moreover, the transcript tree satisfies additional properties: 
	\begin{itemize}
	\item Every root-to-leaf labelled path (i.e., transcript included in the tree) matches the output of $\prover^{*\mathcal{H}'}(x)$ with a partially fresh random oracle $\mathcal{H}'$, and thus has the format of a valid $\Pi_{FS}$ proof with respect to $\mathcal{H}'$.  
	\item For any node $\nu$, the labels $L_{S_\nu}$ on the subtree $S_\nu$ are generated by a $(Q+\mu)$-query random oracle algorithm independently from all labels $L_{\nu^*}$, i.e. labels computed on lower indexed nodes that do not belong to $S_\nu$. In particular, if $\nu$ is the $k$th child of $\omega$ then $L_{S_\nu}$ is independent of the labels on the $(k-1)$-ary left subtree of $\omega$.  
	\end{itemize}
\end{lemma}

Lemma~\ref{lem:FSSoundness} immediately implies that the FS transform of any $k^{(\mu)}$-special sound protocol for $\mathcal{R}$ is knowledge sound in the RO model. However, we need to work a bit harder to apply this lemma to almost-special-sound protocols. We will only be able to show computational knowledge soundness for protocols that are almost-special-sound with respect to a computationally-unique commitment scheme. The DARK proof system has this property. 
\if 0 
\begin{lemma} \label{lem:RODARKSpecial}
If $\Pi(\crs)$ is a $(k^{(\mu)}, \delta, \textsf{com} , \phi)$-almost-special-sound protocol for a relation $\mathcal{R}$ parametrized by $\crs \gets \textsf{com}.\setup(\lambda)$, then there exists a family of predicates $\textsf{P} = \{\rho_i\}_{i \in [\mu]}$ and functions $\{ \textsf{ext}_i\}_{i \in [\mu]}$ where $\textsf{ext}_i: \mathcal{M} \times \mathcal{X}^{\mu - i} \rightarrow \mathcal{M}^{\mu - i}$ and $\rho_i: \mathcal{M}^2 \times \mathcal{X}^{\mu - i} \rightarrow \{0,1\}$ and $\forall i, m_i \in \mathcal{M}$: 
$$\mathbb{P}_{\beta_1,...,\beta_{\mu - i}}[\rho_i(m_i, m_\mu, \beta_1,...,\beta_{\mu - i}) = 1: \textsf{ext}_i(m_i, \beta_1,...,\beta_{\mu - i}) = (m_{i+1},...,m_\mu)] \leq \delta $$
   such that its FS-transform $\Pi^{\mathcal{H}}_{FS}(\crs)$ with random oracle $\mathcal{H}$ is $(k+1)^{(\mu)}$-special sound for the relation: 

$$\mathcal{R}^\mathcal{H}_*(\crs, \textsf{P}) = \{ (\mathsf{x}, \mathsf{w}): (\mathsf{x}, \mathsf{w}) \in \mathcal{R} \cup \mathcal{R}^{\mathcal{H}}_\textsf{ext}(\crs, \textsf{P}) \vee \mathsf{w} \in \mathcal{L}_\textsf{break}(\crs) \} $$ 	
where $\mathcal{L}_\textsf{break}(\crs)$ is defined as in Theorem~\ref{thm:DARKExtractor} and:
$$\mathcal{R}^{\mathcal{H}}_\textsf{ext}(\crs, \textsf{P}) = \left\{(\mathsf{x}, \mathsf{w}) = (\tr, i, M): \begin{array}{c} \tr = (\mathsf{x}, C_1,...,C_\mu) \\ \forall_{j \in [\mu]} \ \alpha_j = \mathcal{H}_\mathsf{x}(C_1,...,C_j) \\ M = ((m_i,o_i),...,(m_\mu, o_\mu)) \\ \forall_{j \geq i} \textsf{com}.\open(\crs,C_j, m_j, o_j) = 1 \\ \textsf{ext}_i(m_i) = (m_{i+1},...,m_\mu) \\ \rho(m_i, m_\mu, \alpha_i,...,\alpha_\mu) = 1  \end{array} \right\} $$ 

\end{lemma}
\fi 

\begin{definition}[RO relation hardness] Let $\mathcal{R}^\mathcal{H}(\crs)$ denote a family of relations parametrized by a random oracle $\mathcal{H}$ and setup $\crs \gets \setup(\lambda)$ with security parameter $\lambda$ where $|\crs| \geq \lambda$. $\mathcal{R}^\mathcal{H}(\crs)$ is $(Q, \epsilon(\lambda))$-hard in the RO model if for any pair of polynomial time random oracle algorithms $\mathcal{A}_1, \mathcal{A}_2$ where $\mathcal{A}_1$ makes at most $Q$ queries to a random oracle $\mathcal{H}'$ (possibly distinct from $\mathcal{H}$) and $\mathcal{A}_2$ makes at most $Q$ queries to random oracle $\mathcal{H}$: 

$$\mathbb{P}\left[(\mathsf{x}, \mathsf{w}) \in \mathcal{R}^\mathcal{H}(\crs): \begin{array}{c} \crs \gets \setup(\lambda) \\ \mathsf{x} \gets \mathcal{A}_1^{\mathcal{H}'}(\crs) \\ \mathsf{w} \gets \mathcal{A}_2^{\mathcal{H}}(\crs, \mathsf{x}) \end{array} \right] \leq \epsilon(\lambda)$$

	
\end{definition}
\benedikt{move this to preliminaries}
\begin{definition}[Computationally Unique Commitments]\label{def:uniqueness} 
	A commitment scheme 
	$\Gamma=(\setup,\commit,\open)$ is computationally-unique if for any polynomial time adversary $\adv$
\[
    \Pr\left[
        b_0 = b_1 =1 \, \wedge \, C_0 \neq C_1 \ : \
        \begin{array}{l}
             \params \gets \pro{Setup}(1^\lambda) \\
             (C_0,C_1, x, r_0, r_1) \gets \adv(\params) \\
             b_0 \gets \pro{Open}(\params, C_0, x, r_0) \\
             b_1 \gets \pro{Open}(\params, C_1, x, r_1) \\
        \end{array}
    \right] \leq \negl \enspace 
\]	 
\end{definition}


\begin{lemma} 
The DARK commitment scheme satisfies computational uniqueness (Definition~\ref{def:uniqueness}) under the adaptive root assumption.
\end{lemma}
\begin{proof}

	Given two commitments to the same message, we will construct a known order element. This element can be used to break the adaptive root assumption. Concretely given an adversary $\adv_{\mathsf{CU}}$ that with non-negligible probability $\epsilon$ outputs $\gr{C}$ and $\gr{C}'$ as well as $h(X)=\frac{f(X)}{N}$ such that $N \cdot \gr{C}=f(q)\cdot \Generator$ and $N \cdot \gr{C}'=f(q)\cdot \Generator$. This implies that $N\cdot (\gr{C}-\gr{C}')=0$, i.e. that $N$ is a multiple of the order of $\gr{C}-\gr{C}'$, which by assumption is a non trivial group element. We can use this to construct an adversary $\adv_{\mathsf{AR}}=(\adv_1,\adv_2)$ for the adaptive root assumption, where $\adv_1$ outputs $\gr{W}=\gr{C}-\gr{C}'$ and $\adv_2$ while $\gcd(N,\ell)\neq 1$ computes $N'\gets N/\gcd(N,\ell^k)$ for $k=\lceil \log_\ell(N)\rceil$ and computes $r\gets \ell^{-1}\bmod N'$ and outputs $\gr{U}\gets \gr{W}^r$. If $\ell$ is co-prime with the order of $\GG$ and thus $\gr{W}$ then $\gr{U}^\ell=\gr{W}^{r\cdot \ell}$ which equals $\gr{W}$ if $N'$ is a multiple of the order of $\gr{U}$. This is the case with overwhelming probability as $N$ is a multiple of the order of $\gr{U}$ and $\ell$ divides the order of $\gr{U}$ with only negligible probability. Thus $\adv_{\mathsf{AR}}$ succeeds with probability $\epsilon-\negl$.
		\end{proof}


\begin{lemma}\label{lem:ExtQHard}
For any $\mu$ and $Q = \poly$, the relation $\mathcal{R}^{\mathcal{H}}_\textsf{ext}(\crs, \mu, \rho)$ defined with respect to any computationally-unique commitment scheme $\mathsf{com}$, predicate $\rho: \mathcal{M}^2 \times \mathcal{X}^\mu \rightarrow \{0, 1\}$, and $\textsf{ext}: \mathcal{M} \times \mathcal{X}^{\leq \mu} \rightarrow \mathcal{M}$ such that $\forall i, m \in \mathcal{M}$: 
$$\mathbb{P}_{\alpha_1,...,\alpha_{\mu}}[\rho_i(m, m_\mu, \alpha_1,...,\alpha_{\mu}) = 1: \textsf{ext}(m, \alpha_1,...,\alpha_{\mu}) = m_\mu] \leq \delta $$
and 

$$\mathcal{R}^{\mathcal{H}}_\textsf{ext}(\crs, \mu, \rho) = \left\{(\mathsf{x} = (C, m, o), \mathsf{w} = (\tr, M)): \begin{array}{c} \tr = (C_1,...,C_\mu) \\ \forall_{i \in [\mu]} \ \alpha_i = \mathcal{H}(C, C_1,...,C_{i-1}) \\ M = ((m_1,o_1),...,(m_\mu, o_\mu)) \\ \textsf{com}.\open(\crs, C, m, o) = 1 \\ \forall_{i \in [\mu]} \textsf{com}.\open(\crs,C_i, m_i, o_i) = 1 \\ \forall_{i \in [\mu]}\textsf{ext}(m, \alpha_1,...,\alpha_{i}) = m_i \\ \rho(m, m_\mu, \alpha_1,...,\alpha_\mu) = 1  \end{array} \right\} $$ 
	
is $(Q, \delta + \negl)$-hard in the RO model. 

\end{lemma}
\begin{proof} 
Consider any pair of polynomial time random oracle algorithms $\mathsf{x} \gets \mathcal{A}_1^{\mathcal{H}'}(\crs)$ 
and $\mathsf{w} \gets \mathcal{A}_2^{\mathcal{H}}(\crs, \mathsf{x})$ that for setup parameter $\lambda$ make at most $Q = \poly$ queries to their respective oracles $\mathcal{H}'$ and $\mathcal{H}$. For fixed $\mathsf{x}$ let $T_\mathcal{H}(\mathsf{x}) = (T_1,...,T_\mu)$ denote a random variable representing the output $\tr$ included in $\mathsf{w}$ \emph{conditioned on} the event that $w$ satisfies \underline{at least} all validity criteria other than possibly the last, i.e. $\rho(m, m_\mu, \alpha_1,...,\alpha_\mu) = 1$. Note that $T_\mathcal{H}(\mathsf{x})$ is also dependent on the randomness of the oracle $\mathcal{H}$. 
Presuming this event occurs with probability at least $\epsilon(\mathsf{x})$, we can repeat $\mathcal{A}_2^\mathcal{H}(\crs, \mathsf{x})$ on fresh internal randomness (not changing $\mathcal{H}$) in expectation $1/\epsilon(\mathsf{x})$ times until it outputs $\mathsf{w}$ satisfying this event with a particular assignment $\tr = (C_1,...,C_\mu)$ to the random variable $T_\mathcal{H}(\mathsf{x})$. Suppose that for any $i \in [\mu]$ we then reprogrammed $\mathcal{H}$ to an oracle $\mathcal{H}^*$ by sampling new answers to any subset of the queries $\{q_j = (C, C_1,...,C_j)\}_{i \leq j < \mu}$ but keeping all other queries consistent with $\mathcal{H}$.  For $i = \mu$ we do not change the oracle and $\mathcal{H}^* = \mathcal{H}$. Define the random variable $T_\mathcal{H^*}(\mathsf{x})$ in the same way for the new oracle $\mathcal{H}^*$. 
Suppose further that repeating the same experiment with $\mathcal{A}_2^\mathcal{H^*}(\crs, \mathsf{x})$ were to return with probability greater than $\delta'(\mathsf{x})$ a vector $\tr'= (C_1',...,C'_\mu) \neq \tr$ where the first distinct index between $\tr'$ and $\tr$ is some $k \leq i$. 
For $i = \mu$ we just repeat the same experiment with $\mathcal{H}$. For all $i \in [\mu]$ let $\alpha_i = \mathcal{H}(C, C_1,...,C_{i-1})$, let $m_i = \textsf{ext}(m, \alpha_1,...,\alpha_i)$, let $\alpha_i' = \mathcal{H}^*(C, C'_1,...,C'_{i-1})$, and let $m'_i = \textsf{ext}(m, \alpha'_1,...,\alpha'_i)$. Since the oracle answers to queries $C$ and $\{q_j = (C, C_1,...,C_\ell)\}_{1 \leq \ell < k}$ have not changed and $(C_1,...,C_{k-1}) = (C_1',...,C'_{k-1})$ it follows that $(\alpha_1,...,\alpha_k) = (\alpha'_1,...,\alpha'_k)$ and $(m_1,...,m_k) = (m'_1,...,m'_k)$. The result of these two experiments would thus include openings of the distinct commitments $C_k \neq C'_k$ to the same message $m_k = m'_k$. 
By computational uniqueness of the commitment scheme, for $\crs \gets \setup(\lambda)$ and $\mathsf{x} \gets \mathcal{A}_1^{\mathcal{H}'}(\crs)$ 
either $\delta'(\mathsf{x})$ or $\epsilon(\mathsf{x})$ is negligible in $\lambda$, as we have shown that it is possible to construct and adversary using $\mathcal{A}_1$ and $\mathcal{A}_2$ that on input $\crs$ breaks the uniqueness of the commitment scheme (Definition~\ref{def:uniqueness})
in expected time $(\frac{1}{\epsilon(\mathsf{x})} + \frac{1}{\delta'(\mathsf{x})}) \cdot \mathsf{\poly}$.
 

We draw two conclusions from this. For $\crs \gets \setup(\lambda)$ and $\mathsf{x} \gets \mathcal{A}_1^{\mathcal{H}'}(\crs)$, if $\mathcal{A}_2^\mathcal{H}(\crs, \mathsf{x})$ succeeds in returning $w$ satisfying the aforementioned event (i.e., all criteria except the last predicate) with non-negligible probability then there is a unique vector $(C_1,...,C_\mu)$ such that: 
\begin{enumerate}[label=(\alph*)]
	\item $\mathbb{P}[T_{\mathcal{H}}(\mathsf{x}) = (C_1,...,C_\mu)] \geq 1 - \negl$
	\item While this unique vector of high support may depend on $\mathcal{H}$, for all $i \in [\mu]$ the first $i$ components $(C_1,...,C_i)$ are independent of the answers to the values $\mathcal{H}(q)$ for $q \in \{(C, C_1,...,C_j)\}_{i \leq j < \mu}$. 
\end{enumerate}
 If (a) were false then running the experiment above for case $i = \mu$ would succeed with non-negligible probability $\delta'$ in returning a distinct assignment to $\mathcal{T}_\mathcal{H}(\mathsf{x})$, which contradicts the computational uniqueness of the commitment scheme as shown above. If (b) were false, then for some $i < \mu$ the experiment would succeed with non-negligible probability $\delta'$ in returning a distinct assignment to $\mathcal{T}_\mathcal{H}(\mathsf{x})$ where the first index of distinction is $k \leq i$, again contradicting the computational uniqueness of the commitment scheme as shown above. 
 
 Finally, (b) implies that $(\alpha_1,...,\alpha_\mu)$ where $\alpha_i = \mathcal{H}(C,C_1,...,C_i)$ is uniformly distributed and hence $\mathbb{P}[\rho(m,m_\mu,\alpha_1,...,\alpha_\mu) = 1] \leq \delta$ as stated in the hypothesis. Thus, conditioned on the event that $w$ satisfies at least all validity criteria except the predicate, then its first component is $\tr = (C_1,...,C_\mu)$ with probability $1-\negl$, in which case it fails the last criteria (i.e., the predicate) with probability $1-\delta$. In conclusion, by a union bound it satisfies all criteria with probability at most $\delta + \negl$. \end{proof}


\if 0 
\begin{lemma} 
The relation $\mathcal{R}^{\mathcal{H}}_\textsf{ext}(\crs, \textsf{P})$ defined in Lemma~\ref{lem:RODARKSpecial} with respect to any computationally-unique commitment scheme $\mathsf{com}$ and $\textsf{P} = \{\rho_i\}_{i \in [\mu]}$ and $\{ \textsf{ext}_i\}_{i \in [\mu]}$ where $\textsf{ext}_i: \mathcal{M} \times \mathcal{X}^{\mu - i} \rightarrow \mathcal{M}^{\mu - i}$ and $\rho_i: \mathcal{M}^2 \times \mathcal{X}^{\mu - i} \rightarrow \{0,1\}$ such that $\forall i, m_i \in \mathcal{M}$: 
$$\mathbb{P}_{\beta_1,...,\beta_{\mu - i}}[\rho_i(m_i, m_\mu, \beta_1,...,\beta_{\mu - i}) = 1: \textsf{ext}_i(m_i, \beta_1,...,\beta_{\mu - i}) = (m_{i+1},...,m_\mu)] \leq \delta $$
is $(Q, Q \cdot \delta + \negl)$-hard in the RO model. 
\end{lemma}
\fi 

\begin{theorem}
\label{thm:uniquefs}
	If $\Pi$ is a $(k^{(\mu)}, \delta, \textsf{com} , \phi)$-almost-special-sound protocol for a relation $\mathcal{R}$ and a computationally-unique commitment scheme $\textsf{com}$ (Definition~\ref{def:uniqueness}) whose setup runs $\crs \gets \textsf{com}.\setup(\lambda)$ then its FS transform $\Pi_{FS}$ is an argument of knowledge for $\mathcal{R}$ in the RO model (Definition~\ref{def:ROargument}) with knowledge error: 
	 $$\textsf{err}(\lambda, Q) = \frac{(Q+1)\kappa}{1- \kappa}  + 2\lambda (k^\mu + Q \cdot (k^\mu - 1)) \cdot \delta + \negl
 $$ where $\kappa = 1 - (1 - \frac{k}{2^\lambda})^\mu$.
	\end{theorem}
	\begin{proof}
	Let $\verifier^\mathcal{H}$ denote the resulting verifier for $\Pi_{FS}$. We will construct an extractor $\mathcal{E}$ which is given black-box access to any \emph{deterministic} $Q$-query prover algorithm $\prover^*$, where $Q$ is assumed to be polynomial in $\lambda$. $\mathcal{E}$ has the power to intercept and respond to the queries $\prover^*$ makes to the random oracle, simulating (i.e., reprogramming) the oracle responses. On input $x$ and parameters $\crs$, $\mathcal{E}$ first tests that $\prover^*$ outputs a proof $\pi$ such that $\verifier^\mathcal{H}(\crs, x, \pi) = 1$ and otherwise aborts. If this first step succeeds, then $\mathcal{E}$ continues by running the tree generation algorithm from Lemma~\ref{lem:FSSoundness} to generate a $(k+1)$-ary forking transcript tree. Given black-box access to a deterministic $Q$-query prover algorithm, this tree generation algorithm runs in expected polynomial time $k^\mu + Q \cdot (k^\mu - 1)$ succeeding with probability $\frac{\epsilon(x) - (Q+1) \cdot \kappa }{(1 - \kappa)}$ where $\kappa = 1 - (1 - \frac{k}{2^\lambda})^\mu$ and $\epsilon(x)$ is the probability over the randomness of $\mathcal{H}$ that $\prover^*$ outputs a non-interactive proof that $\verifier^\mathcal{H}$ accepts. $\mathcal{E}$ will repeat $\lambda$ iterations of running this tree generation algorithm for $2 (k^\mu + Q \cdot (k^\mu - 1))$  steps each time, and returns the first trial that succeeds. By Markov, this results in a new tree generation algorithm that runs in strict polynomial time $2\lambda (k^\mu + Q \cdot (k^\mu - 1))$ with negligible loss $2^{-\lambda}$ in its probability of success.
	
	 For any $(k+1)$-ary transcript tree, there is a polynomial time procedure (Definition~\ref{def:TreeExtract}) which as shown in Lemma~\ref{lem:DARKExtractor} either: 
	 \begin{enumerate}[label=(\alph*)]
	 	\item Extracts a witness $w$ such that $(x, w) \in \mathcal{R}$
	 	\item Extracts a break to the binding of the commitment scheme, i.e. an element of $\mathcal{L}_\textsf{break}(\crs)$ defined in Theorem~\ref{thm:DARKExtractor}.
	 	\item Extracts an opening $(m_\omega, o_\omega)$ for the commitment label on some node $\omega$ at some level $i$ with rightmost child $\nu$ at level $i+1$ such that $\phi_b(i, m_\omega) = 1$, $\phi_a(i, m_\omega) = 0$, openings of all commitment labels on the leftmost path $\textsf{lpath}(\nu)$ extending down from $\nu$ to messages equal to $\textsf{Extend}(i, m, \alpha_i,...,\alpha_\mu) = (m_i,...,m_\mu)$ where $(\alpha_i,...,\alpha_\mu)$ are the verifier challenges along this path such that $\forall_{j \geq i} \phi_a(j, m_j) = 1$. 
	 \end{enumerate}
	 
	 The third extraction event was ruled out (with overwhelming probability) from any transcript tree generated via the Path Predicate Forking Lemma, see Theorem~\ref{thm:DARKExtractor} and Lemma~\ref{lem:ppfl}. In particular, the transcript tree generated there was shown to satisfy a predicate (with overwhelming probability) that eliminates the possibility that $\phi_a(i, m_\omega) = 0$ yet $\phi_a(\mu, m_\mu) = 1$. The analysis leveraged the way that transcripts are sampled by that tree generation algorithm. However, we will need to use a slightly different analysis this time.  
	 
	 First, we define the relation for all $i \in [\mu]$, commitment scheme parameters $\crs$, and random oracle $\mathcal{H}^*$: 
	 $$\mathcal{R}^{\mathcal{H^*}}_\textsf{ext}(\crs, \mu - i) = \left\{(\mathsf{x} = (C, m, o), \mathsf{w} = (\tr, M)): \begin{array}{c} \tr = (\mathsf{x}, C_1,...,C_{\mu-i}) \\ \forall_{j \in [\mu-i]} \ \alpha_j = \mathcal{H}^*(C,C_1,...,C_{j-1}) \\ M = ((m_1,o_1),...,(m_{\mu-i}, o_{\mu-i})) \\ \forall_{j \in [\mu-i]} \textsf{com}.\open(\crs,C_j, m_j, o_j) = 1 \\ \textsf{Extend}(i,m,\alpha_1,...,\alpha_{\mu-i}) = (m_1,...,m_{\mu - i}) \\ \phi_b(i,m) = 1, \phi_a(i, m) = 0, \phi_a(\mu, m_{\mu - i}) = 1  \end{array} \right\} $$
	 We note that by Lemma~\ref{lem:FSSoundness}, in case (c) occurs, there is a $(Q+\mu)$-query polynomial time algorithm $\mathcal{A}_1$ that generates $(C,m,o)$ and transcript prefix $\mathbf{y}$, and an independent $(Q + \mu)$-query adversary $\mathcal{A}_2^{\mathcal{H}^*}$ which generates the witness $(\tr, M)$ such that $((C, m, o), (\tr, M)) \in \mathcal{R}^{\mathcal{H}^*_\mathbf{y}}_\textsf{ext}(\crs, \mu - i)$ for some $i$. $\mathcal{A}_1$ represents the algorithm that ran the partial tree generation that created all labels on the left $k$-ary subtree of $\omega$ and also the prefix $\mathbf{y}$ labeling the trunk (i.e., from root to $\omega$) of subtree $S_\nu$, and then also ran the tree extraction algorithm (Definition~\ref{def:TreeExtract}) on this left $k$-ary subtree of $\omega$. Note that conditioned on event (c), $\omega$ is the first node and index $i$ for which this tree extraction succeeds in producing an opening $(m_\omega, o_\omega)$ such that $\phi_b(i, m_\omega) = 1$ but $\phi_a(i, m_\omega) = 0$. By Lemma~\ref{lem:FSSoundness} the root-to-leaf path that includes the prefix $\mathbf{y}$ and $\textsf{lpath}(\nu)$ matches the output of some $\mathcal{A}_*^{\mathcal{H}^*}(x)$ with partially fresh random oracle $\mathcal{H}^*$, and there is also a subtree generation algorithm that is a $(Q+\mu)$-query algorithm which generated the labels on subtree $S_\nu$. $\mathcal{A}^{\mathcal{H}^*}_2$ represents the combination of these two algorithms and also the subtree extractor that opens the commitments on these labels. Conditioned on $(c)$, the openings of the commitment labels within this subtree all satisfy predicate $\phi_a$ and the opened messages of the commitment labels $\textsf{lpath}(\nu)_0$ along the leftmost path from $\nu$ match the output of $\textsf{Extend}(i, m, \textsf{lpath}(v)_1)$ where $\textsf{lpath}(\nu)_1$ are the challenge labels along this path. 
	 
	 
	 Let $\rho_i$ denote the predicate such that $\rho_i(m, m', \alpha_1,...,\alpha_{\mu - i}) = 1 $ iff $\phi_b(i, m) = 1$, $\phi_a(i, m) = 0$, and $\phi_a(\mu, m') = 1$. By the definition of $(k^{(\mu)}, \delta, \textsf{com} , \phi)$-almost-special-soundness, for uniform random $\beta_1,...,\beta_{\mu -i}$: 
	 $$\mathbb{P}_{\beta_1,....,\beta_{\mu -i}}[\rho(m, m_{\mu - i},\beta_1,...,\beta_{\mu - i}) = 1 : \textsf{Extend}(i,m,\beta_1,...,\beta_{\mu-i}) = (m_1,...,m_{\mu - i})] \leq \delta $$ 
	 Thus, since $Q+\mu$ is polynomial in $\lambda$, by Lemma~\ref{lem:ExtQHard} the relation $\mathcal{R}^{\mathcal{H^*}}_\textsf{ext}(\crs, \mu - i)$ is $(Q+\mu, \delta + \negl)$-hard in the RO model for $Q = \poly$. This shows that for any particular index in the transcript tree, the event of type (c) occurs with probability at most $\delta +\negl$ when running the extractor with polynomial time provers making a polynomial number of queries to the RO. This experiment may effectively occur times over the course of the tree generation algorithm, but we can loosely union bound the probability that event (c) ever occurs by the runtime of the tree generation algorithm. Similarly, we can eliminate event (b) as occurring with $\negl$ by the computational binding property of the commitment scheme, which does not require an additional union bound.  
	 
	 Finally, letting $\epsilon(x, \st)$ denote the probability over the parameters and random oracle that the verifier accepts the proof $\pi$ output by $P^*(\st)$ for public input $x$, we conclude that: 
	
	 \begin{small}
 \begin{align*}
	\mathbb{P} \left[
	\begin{array}{c} 
	(x,w) \in \mathcal{R} \ and \\\ 
    \verifier^\mathcal{H}(\crs, x, \pi) = 1 
	\end{array} : 
	\begin{array}{c}
	\crs \gets \setup(\lambda) \\
	(x, \st) \gets \mathcal{A}(\crs) \\ 
	\pi \gets P^*(\st) \\ 
	w \gets \mathcal{E}^{P^*(\st)}(\crs, x) 
	\end{array}
 \right] = \mathbb{P} \left[
	\begin{array}{c} 
	(x,w) \in \mathcal{R}  
	\end{array} : 
	\begin{array}{c}
	\crs \gets \setup(\lambda) \\
	(x, \st) \gets \mathcal{A}(\crs) \\ 
	\pi \gets P^*(\st) \\ 
	w \gets \mathcal{E}^{P^*(\st)}(\crs, x) 
	\end{array}
 \right] \\   
 \geq \sum_{x, \st} \left(\frac{\epsilon(x, \st) - (Q+1)\kappa}{1-\kappa} - 2\lambda (k^\mu + Q \cdot (k^\mu - 1))\cdot \delta - \negl\right) \cdot \mathbb{P} \left[ \mathcal{A}(\crs) = (x, \st) :
	\crs \gets \setup(\lambda) \right] \\
 \geq \mathbb{P} \left[
	\begin{array}{c} 
	\verifier^\mathcal{H}(\crs, x, \pi) = 1 
	\end{array} : 
	\begin{array}{c}
	\crs \gets \setup(\lambda) \\
	(x, \st) \gets \mathcal{A}(\crs) \\ 
	\pi \gets P^*(\st) \\ 
	\end{array}
 \right] - \frac{(Q+1)\kappa}{1- \kappa} -2\lambda (k^\mu + Q \cdot (k^\mu - 1)) \cdot \delta - \negl
	\end{align*}
	\end{small}

The first equality holds because $\mathcal{E}^{\prover^*(\st)}(\crs, x)$ aborts in its first step if the deterministic $\prover^*(\st)$ outputs $\pi$ such that $\verifier^\mathcal{H}(\crs, x, \pi) \neq 1$. %Since $\kappa = 1 - (1 - \frac{k}{2^\lambda})^\mu$, $k$ is a constant, and $Q$ is bounded by a polynomial in $\lambda$, the knowledge error term reduces to $2\lambda (k^\mu + Q \cdot (k^\mu - 1)) \cdot \delta + \textsf{negl}'(\lambda)$ for a negligible function $\textsf{negl}'$.  
	 %In conclusion, for any prover $P^*$ that succeeds in convincing the verifier with non-negligible probability for an input $x$ generated by the polynomial time adversary $\mathcal{A}$ on freshly sampled setup parameters $\crs \gets \setup(\lambda)$, the extractor succeeds in polynomial time to return $(x, w) \in \mathcal{R}$ except with $\negl$. 
	 \end{proof}





\section*{Polynomial IOP Compilation}
\section{Proof of Theorem~\ref{thm:IOPcompiler} (Polynomial IOP Compilation)}\label{sec:IOPcompilerproof}


\def\thetheorem{\ref{thm:IOPcompiler}}
\begin{theorem}
\theoremIOPcompiler
\end{theorem}

The fact that the compilation preserves HVZK is straightforward. We prove this part first and then move on to proving witness-extended emulation. 

\paragraph{HVZK}
\begin{proof} Let $S_\eval$ denote the HVZK simulator for $\eval$ and $S_\pro{IOP}$ denote the HVZK simulator for the original polynomial IOP. We construct an HVZK simulator $S$ for the compiled interactive argument as follows. 
$S$ begins by running $S_\pro{IOP}$ on the input $x$, which produces a series of query/response pairs to arbitrarily labeled oracles that are ``sent" from the IOP prover to the verifier. $S$ simulates the view of the honest verifier in the compiled interactive proof by replacing each distinctly labeled oracle with a fresh $\Gamma$ commitment to $0$, \emph{i.e.}, the zero polynomial over $\FF_p$. By the hiding property of $\Gamma$ this has negligible distance $\delta_0$ from the commitment sent in the real protocol.
(It places this commitment at the location in the transcript where the commitment to this oracle would be sent in the compiled protocol).
 For each query/response pair $(z, y)$ to an oracle, $S$ runs $S_\eval$ to simulate the view of an honest-verifier in the $\eval$ protocol opening a hiding polynomial commitment to the value $y$ at the point $z$. Let $P$ denote an upper bound on the total number of oracles sent and $Q$ denote an upper bound on the total number of queries to IOP oracles. 
If the simulation of $S_\pro{IOP}$ has statistical distance $\delta_1$ from the real IOP verifier's view, and each simulated $\eval$ subprotocol has statistical distance $\delta_2$ to the real $\eval$ verifier's view, then the output of $S$ has statistical distance at most $P \delta_0 + \delta_1 + Q \delta_2$ from $\textsf{View}_{\langle P(x, w), V(x) \rangle}$. For $P, Q < \poly$ and $\delta_0, \delta_1, \delta_2 < \negl$ this statistical distance is negligible in $\lambda$. 
\end{proof}

\paragraph{Witness-extended emulation (knowledge)}

\begin{proof}
Without loss of generality, assume the original IOP makes at least one query to each oracle sent. An oracle which is never queried can be omitted from the IOP.

We denote by $\verifier$ the IP verifier for the compiled IP, and $\verifier_{O}$ the verifier for the original IOP. 
Given a record oracle $\pro{Record}(P^*, \params, x, \st)$ for an IP prover $P^*$ that produces accepting transcripts with non-negligible probability, we build an emulator $E$ for the compiled IP. $E$ begins by constructing an IOP adversary $P'_{O}$, which succeeds also with non-negligible probability on input $x$. Every successful interaction of $P'_{O}$ with $\verifier_{O}$ on input $x$ corresponds to a successful transcript of $P^*$ with $V$ on $x$. In showing how $E$ builds $P'_{O}$ we also show how $E$ can obtain this corresponding transcript. $E$ will make use of the emulator $E_\eval$ for the commitment scheme $\Gamma$. %We will describe how this is done in the later parts of the proof. Accepting that this is true. 

Finally, $E$ can use the IOP knowledge extractor $E_{\pro{IOP}}^{P'_O}(x)$ in order to output a witness for $x$ along with the corresponding transcript. 

\paragraph{Constructing $P'_O$ (IOP adversary)}
$P'_O$ runs as follows on initial state $\st_0$ and input $x$. It internally simulates the interaction of $P^*$ and $V$, using the record oracle $\pro{Record}(P^*, \params, x, \st)$. It begins by running this for the first round on state $\st_0$. For every message that $P^*$ sends in this first round, $P'_O$ continues simulation until there is an $\eval$ on this commitment. (There is guaranteed to be at least one $\eval$ on each commitment, independent of the randomness). Therefore, denoting by $E_\eval$ the extractor for the $\eval$ subprotocol between $P^*$ and $\verifier$ on a given commitment and evaluation point, the record oracle can be used to simulate $E_\eval$'s record oracle.% for each $m$ evaluated at some point determined by $V$'s challenge.

For each message $m$ that $P^*$ sends to $V$ at the beginning of the first round, $P'_O$ interprets $m$ as a commitment, and attempts to extract from it a polynomial by 
running the PPT emulator $E_\eval$, simulating its record oracle as just described. \textbf{If it fails in any extraction attempt it aborts.} 

If $P'_O$ succeeds in all these extractions, then it uses these extracted polynomials as its first round proof oracles that it gives to $\verifier_O$. Upon receiving the first public-coin challenge from the IOP verifier, $P'$ uses the query function to derive the corresponding queries to each of these proof oracles. Before answering, it rewinds $P^*$ and $\verifier$ back to the point immediately after $P$ sent its first messages, and now substitutes random challenge from $\verifier_O$ in order to simulate $P^*$ and $V$ on these same queries. It checks that $P^*$'s answers are consistent with the answers it can compute on its own from the extracted polynomials. \textbf{If any answers are inconsistent, $P'_O$ aborts}. Otherwise, it sends the answers to $\verifier_O$. 

At the end of this first round (assuming $P'$ has not yet aborted), $P'_O$ has stored an updated state $\st'$ for $P^*$ based on this simulation. It proceeds to the next round and repeats the same process, using the record oracle $\pro{Record}(P^*, \params, x, \st')$. Finally, if $P'$ makes it through all rounds without aborting, then it has a final state $\st_V$ for $\verifier_O$ based on its internal simulation of $P^*$ and $V$ up through the end of the last round. Finally, $\verifier_O(\st_V)$ outputs $\pro{Accept}$ or $\pro{Reject}$. %(Observe that $\verifier_O$ accepts if and only if $\verifier$ would accept in the simulated transcript with $P^*$ because they run the same decision algorithm on the final state of query/response pairs). % $1$ on $\st_V$. (This is due to the fact that the verifier in the compiled IOP runs the same final decision algorithm as the IOP verifier). 

\paragraph{Analysis of $P'_O$ success probability} 
We claim that if $\pro{Record}(P^*, \params, x, \st_0)$ outputs an accepting transcript $\tr$ with non-negligible probability, then $P'_O$ succeeds with non-negligible probability. 

Observe that for any accepting $\tr$ between $P^*$ and $V$, if $P'_O$ happens to follow the same exact sequence of query/responses without ever aborting then it succeeds because $\verifier_O$ and $\verifier$ run the same decision algorithm on the final state of query/response pairs. Thus, it remains only to take a closer look at what events cause $P'_O$ to abort, and bound the fraction of accepting $\tr$ for which this occurs. 

As indicated in bold above, there are two kinds of events that cause $P'_O$ to abort: 
\begin{itemize}
\item It fails to extract from a ``commitment" message $m$ sent by $P^*$
\item After successfully extracting a polynomial $f$ from a commitment, $P^*$ answer queries to $f$ in a way that is inconsistent with $f$. 
\end{itemize}

The second type of event contradicts the evaluation binding property of $\Gamma$, therefore it occurs with negligible probability. 

To analyze the first type of event, let us define ``bad commitments" for a parameter $D$. We define this as a property of a message $m$ (purportedly a commitment) sent in a transcript state $\st$.

\paragraph{Bounding probability of commitment extraction failure} 
The pair $(m, \st)$ is a ``bad commitment" if there is less than a $1/D$ probability that extending the transcript between $P^*$ and $\verifier$, starting from state $\st$, will contain a successful execution of $\eval$ on $m$. This probability is over the randomness of the public-coins of $\verifier$ in the extended transcript. %have a succesful execution on (over the randomness of the public-coins) that $\pro{Record}(P^*, \params, x, \st)$ contains a successful execution of $\eval$ on $m$ on the queries defined by $\st$ and the next public coin challenge, where $\st$ is determined by running $\tr$ up until the point $m$ appears. 


Let $A(\tr)$ denote the event that a transcript $\tr$ sampled from $\pro{Record}(P^*, \params, x, \st_0)$ is accepting. Let $B(\tr)$ denote the event that $\tr$ contains a ``bad commitment" (i.e. some message $m$ sent in state $\st$ such that $\pro{Bad}(m, \st) = 1$). The conditional probability of event $A(\tr)$ conditioned on event $B(\tr)$ is less than $1/D$. To see this, fix $(m, \st)$ with $\pro{Bad}(m, \st) = 1$ and consider ``sampling" a random $\tr$ that contains $m$ at state $\st$. This is done by first choosing randomly from all partial transcripts that result in $(m, \st)$ via brute force, and then running the transcript normally from state $\st$ on random public-coins. No matter how $(m, \st)$ is chosen, the probability that this process produces an accepting transcript is by definition less than $1/D$. (The second part of the transcript following $(m, \st)$ contains at least one execution of $\eval$ on $m$ by hypothesis, and by the definition of $B(m, \st) = 1$ this execution is accepting with probability less than $1/D$).

Assume that $P(A(\tr)) \geq 1/\poly$. Applying Bayes' law, %letting $A(\tr)$ denote the event that $\tr$ is accepting and $P(A(\tr)) > 1/\poly$ the a-priori probability of this event, 
\[ P[B(\tr) | A(\tr)) \leq \frac{ P[A(\tr) | B(\tr)] }{ P(A(\tr)) } \leq \poly / D \enspace . \]
In other words, at least a $1 - \poly/D$ fraction of accepting transcripts do not contain ``bad commitments". %By a union bound, in a length $L$ transcript void of bad commitments, the transcript does not contain any failed $\eval$ with probability at least $L/B$. 
Furthermore, so long as a commitment $m$ is not ``bad", we can invoke the witness-emulation property of $\eval$ to say that the PPT $E_\Gamma$ emulator extracts a witness polynomial from each $m$ with overwhelming probability.


Setting $D = 2 \poly$ we get that on at least a $1/2$ fraction of accepting transcripts, $P'_O$s simulation also succeeds (i.e. successfully extracts from each prover commitment message) with probability at least $1/2$. This means that $P'_O$ has a non-negligible success probability conditioned on the event that $\tr$ is an accepting transcript. 

In conclusion, if $\tr$ is accepting with non-negligible probability, then there is a non-negligible probability that $P'_O$ succeeds. 
\end{proof}

%\ifappendix
%\section{Other Instantiations of Polynomial IOPs} \label{appendix:other_polynomial_iops}

%\input{sections/other_polynomial_iops}
%\fi




